{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Login to Hugging Face",
   "id": "d4c273c06c9df7f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token, # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "520f95e7e63f816"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "# datasets\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "id": "9235535ed4854c5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "22362d4225312f7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "id": "93a3fd4f90f6eb29"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameters",
   "id": "816905249628d700"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# seed\n",
    "seed=42\n",
    "\n",
    "# Tokenizer arguments\n",
    "max_length=32 # maximum length of the text that can go to the model\n",
    "padding=\"max_length\" # padding strategy: \"longest\", \"max_length\", \"do_not_pad\"\n",
    "truncation=True # truncate the text if it exceeds the maximum length\n",
    "\n",
    "# mixed precision\n",
    "dtype=torch.bfloat16 # data type\n",
    "\n",
    "# training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\", # output directory\n",
    "    logging_dir=\"./logs\", # logging directory\n",
    "    save_strategy=\"epoch\", # save strategy\n",
    "    logging_strategy=\"epoch\", # logging strategy\n",
    "    evaluation_strategy=\"epoch\", # evaluation strategy\n",
    "    metric_for_best_model=\"loss\", # metric for best model\n",
    "    save_total_limit=1, # save total limit\n",
    "    greater_is_better=False, # greater is better\n",
    "    load_best_model_at_end=True, # load best model at the end\n",
    "\n",
    "    learning_rate=2e-5, # learning rate\n",
    "    num_train_epochs=5, # number of training epochs\n",
    "    per_device_train_batch_size=1, # training batch size\n",
    "    per_device_eval_batch_size=1, # evaluation batch size\n",
    "    optim=\"adamw_torch\", # optimizer\n",
    "    weight_decay=0.01, # weight decay\n",
    "    lr_scheduler_type=\"cosine\", # learning rate scheduler\n",
    "    seed=seed # seed\n",
    ")\n",
    "\n",
    "# validation split\n",
    "validation_size=0.1"
   ],
   "id": "31e5350df012568f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "13af7b257e37de1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model_id = \"deepseek-ai/deepseek-math-7b-rl\"",
   "id": "dec876c78d608f1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=dtype\n",
    ")"
   ],
   "id": "2b0f781b0da0b1a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model",
   "id": "cb5a8d6b9ab17d6c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "75ef6e180d2fea5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f310cd39db90251c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "b92890f3bd0a99b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d26ba972cb5f47ed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "17be569c1363850d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
