{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Login to Hugging Face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c2f9104252a4bb"
  },
  {
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token, # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:10:43.746642Z",
     "start_time": "2024-04-10T12:10:43.139759Z"
    }
   },
   "id": "4eee58c68eb02d85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/pathfinder/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "42e039847db63c95"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Downloads"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78114e8f78ee19ec"
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install huggingface_hub\n",
    "#!pip install transformers\n",
    "#!pip install bitsandbytes\n",
    "#!pip install peft\n",
    "#!pip install trl\n",
    "#!pip install accelerate\n",
    "#!pip install datasets\n",
    "#!pip install scikit-learn\n",
    "#!pip install packaging\n",
    "#!pip install ninja\n",
    "#!pip install flash-attn --no-build-isolation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:10:43.749955Z",
     "start_time": "2024-04-10T12:10:43.747718Z"
    }
   },
   "id": "ce6454f84604b9e4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "65057e5f43e80862"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "685ac8c0e05ac872"
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# datasets\n",
    "import pandas as pd\n",
    "from datasets import Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:10:47.727745Z",
     "start_time": "2024-04-10T12:10:43.750999Z"
    }
   },
   "id": "f8c108abcd576306",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e512d30c21d105c2"
  },
  {
   "cell_type": "code",
   "source": [
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:10:47.731900Z",
     "start_time": "2024-04-10T12:10:47.729239Z"
    }
   },
   "id": "fdf3a2a4e0e31554",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84ce31a12e172a64"
  },
  {
   "cell_type": "code",
   "source": [
    "# seed\n",
    "seed=42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Tokenizer arguments\n",
    "max_length=512\n",
    "padding=\"max_length\"\n",
    "truncation=True\n",
    "\n",
    "# model arguments\n",
    "max_new_tokens=100\n",
    "\n",
    "# mixed precision\n",
    "dtype=torch.bfloat16\n",
    "\n",
    "# quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=dtype,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_doulbe_quant=True\n",
    ")\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "# training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    logging_dir=\"./logs\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    save_total_limit=1,\n",
    "    \n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"adamw_torch\",\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0,\n",
    "    warmup_steps=0,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# train-validation split\n",
    "validation_size=0.1\n",
    "\n",
    "# SFTTrainer arguments\n",
    "max_seq_length=512"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:10:47.747322Z",
     "start_time": "2024-04-10T12:10:47.732792Z"
    }
   },
   "id": "dc1a272a1c0b7ce4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5d3b7c47ea29a3d"
  },
  {
   "cell_type": "code",
   "source": [
    "# Model List\n",
    "\n",
    "# gemma variants\n",
    "\n",
    "# llama2 variants\n",
    "\n",
    "# phi variants\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:10:47.750635Z",
     "start_time": "2024-04-10T12:10:47.748317Z"
    }
   },
   "id": "70d2fbe5c0980a54",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "model_id = \"google/gemma-7b-it\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:10:47.757147Z",
     "start_time": "2024-04-10T12:10:47.751853Z"
    }
   },
   "id": "eb8160d8919cdaeb",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": "model_save_path = \"model\"",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:10:47.764095Z",
     "start_time": "2024-04-10T12:10:47.758094Z"
    }
   },
   "id": "9076eb421a800a65",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:10:48.458072Z",
     "start_time": "2024-04-10T12:10:47.765031Z"
    }
   },
   "id": "825b9aa8bd40db56",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=dtype,\n",
    "    quantization_config=quantization_config,\n",
    "    trust_remote_code=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:15.629236Z",
     "start_time": "2024-04-10T12:10:48.460288Z"
    }
   },
   "id": "4ebbf883fce9aa8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7130a2143144b70957de9eeddc2c9b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:15.634575Z",
     "start_time": "2024-04-10T12:11:15.630428Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "549b02b48bf630b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaForCausalLM(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 3072, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x GemmaDecoderLayer(\n",
       "        (self_attn): GemmaFlashAttention2(\n",
       "          (q_proj): Linear4bit(in_features=3072, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=3072, out_features=4096, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=3072, out_features=4096, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=3072, bias=False)\n",
       "          (rotary_emb): GemmaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): GemmaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=3072, out_features=24576, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=3072, out_features=24576, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=24576, out_features=3072, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): GemmaRMSNorm()\n",
       "        (post_attention_layernorm): GemmaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): GemmaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": "## Dataset",
   "metadata": {
    "collapsed": false
   },
   "id": "a4042d4b7cd2d0fd"
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset Path\n",
    "train_dataset_path1 = \"dataset/llm-prompt-recovery-synthetic-datastore/gemma1000_w7b.csv\"\n",
    "train_dataset_path2 = \"dataset/3000-rewritten-texts-prompt-recovery-challenge/prompts_0_500_wiki_first_para_3000.csv\"\n",
    "test_dataset_path = \"data-sample/test.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:15.641166Z",
     "start_time": "2024-04-10T12:11:15.635790Z"
    }
   },
   "id": "296981ef806ae29a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "# `LLM Prompt Recovery - Synthetic Datastore dataset` by @dschettler8845\n",
    "df1 = pd.read_csv(train_dataset_path1)\n",
    "df1 = df1[[\"original_text\", \"rewrite_prompt\", \"gemma_7b_rewritten_text_temp0\"]]\n",
    "df1 = df1.rename(columns={\"gemma_7b_rewritten_text_temp0\":\"rewritten_text\"})\n",
    "df1.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:15.717325Z",
     "start_time": "2024-04-10T12:11:15.642416Z"
    }
   },
   "id": "87aae83b855f06af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                       original_text  \\\n",
       "0  Port-au-Prince, Haiti (CNN) -- Earthquake vict...   \n",
       "1  Former secretary of state Hillary Clinton meet...   \n",
       "2  The opinions expressed by columnists are their...   \n",
       "3  BIGBANG is one of those musical entities that ...   \n",
       "4  WHAT?!??! I know. That’s what you’re saying ri...   \n",
       "\n",
       "                                      rewrite_prompt  \\\n",
       "0        Turn this into an association to be joined.   \n",
       "1             Convert this into a gain to be gained.   \n",
       "2                  Frame this as a political debate.   \n",
       "3        Imagine this as a mathematician's equation.   \n",
       "4  Frame this as an accountant's thrilling advent...   \n",
       "\n",
       "                                      rewritten_text  \n",
       "0  Sure, here is the association you requested:\\n...  \n",
       "1  Sure, here is the gain to be gained from the t...  \n",
       "2  ## The Obama Legacy: A Tale of Two Sides\\n\\nTh...  \n",
       "3  Sure, here is the equation:\\n\\n**BIGBANG's imp...  \n",
       "4  Sure, here's the framed text as an accountant'...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>rewrite_prompt</th>\n",
       "      <th>rewritten_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Port-au-Prince, Haiti (CNN) -- Earthquake vict...</td>\n",
       "      <td>Turn this into an association to be joined.</td>\n",
       "      <td>Sure, here is the association you requested:\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Former secretary of state Hillary Clinton meet...</td>\n",
       "      <td>Convert this into a gain to be gained.</td>\n",
       "      <td>Sure, here is the gain to be gained from the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The opinions expressed by columnists are their...</td>\n",
       "      <td>Frame this as a political debate.</td>\n",
       "      <td>## The Obama Legacy: A Tale of Two Sides\\n\\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIGBANG is one of those musical entities that ...</td>\n",
       "      <td>Imagine this as a mathematician's equation.</td>\n",
       "      <td>Sure, here is the equation:\\n\\n**BIGBANG's imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WHAT?!??! I know. That’s what you’re saying ri...</td>\n",
       "      <td>Frame this as an accountant's thrilling advent...</td>\n",
       "      <td>Sure, here's the framed text as an accountant'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "# `3000 Rewritten texts - Prompt recovery Challenge` by @dipamc77\n",
    "df2 = pd.read_csv(train_dataset_path2)\n",
    "df2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:15.756826Z",
     "start_time": "2024-04-10T12:11:15.718257Z"
    }
   },
   "id": "6c22936e72124f4a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                       original_text  \\\n",
       "0  Sfiso Ncwane (April 21, 1979 - December 5, 201...   \n",
       "1  The 1959–60 California Golden Bears men's bask...   \n",
       "2  Franck Passi (born 28 March 1966) is a French ...   \n",
       "3  Hollandaea diabolica is a species of Australia...   \n",
       "4  The QF 6-inch Gun Mark N5 (initially designate...   \n",
       "\n",
       "                                      rewrite_prompt  \\\n",
       "0  Transform the text into a series of riddles th...   \n",
       "1  Make this a market entry strategy for a new re...   \n",
       "2  Write it as the last chapter of a book that ch...   \n",
       "3  Turn it into a vaudeville stage act introduction.   \n",
       "4  Transform the text into a series of instructio...   \n",
       "\n",
       "                                      rewritten_text  \n",
       "0  Sure, here's the text transformed into riddles...  \n",
       "1  ## Market Entry Strategy: Launching a Brand in...  \n",
       "2  ## The Final Chapter: Ode to a Changed Soul\\n\\...  \n",
       "3  **Vaudeville Stage Act Introduction:**\\n\\nLadi...  \n",
       "4  The text does not provide any information abou...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>rewrite_prompt</th>\n",
       "      <th>rewritten_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sfiso Ncwane (April 21, 1979 - December 5, 201...</td>\n",
       "      <td>Transform the text into a series of riddles th...</td>\n",
       "      <td>Sure, here's the text transformed into riddles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The 1959–60 California Golden Bears men's bask...</td>\n",
       "      <td>Make this a market entry strategy for a new re...</td>\n",
       "      <td>## Market Entry Strategy: Launching a Brand in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Franck Passi (born 28 March 1966) is a French ...</td>\n",
       "      <td>Write it as the last chapter of a book that ch...</td>\n",
       "      <td>## The Final Chapter: Ode to a Changed Soul\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hollandaea diabolica is a species of Australia...</td>\n",
       "      <td>Turn it into a vaudeville stage act introduction.</td>\n",
       "      <td>**Vaudeville Stage Act Introduction:**\\n\\nLadi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The QF 6-inch Gun Mark N5 (initially designate...</td>\n",
       "      <td>Transform the text into a series of instructio...</td>\n",
       "      <td>The text does not provide any information abou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "# Merge all datasets\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "#df = df.sample(2000).reset_index(drop=True) # to reduce training time we are only using 2k samples\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:15.763645Z",
     "start_time": "2024-04-10T12:11:15.757946Z"
    }
   },
   "id": "4c7fcbf5e913f1a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                       original_text  \\\n",
       "0  Port-au-Prince, Haiti (CNN) -- Earthquake vict...   \n",
       "1  Former secretary of state Hillary Clinton meet...   \n",
       "2  The opinions expressed by columnists are their...   \n",
       "3  BIGBANG is one of those musical entities that ...   \n",
       "4  WHAT?!??! I know. That’s what you’re saying ri...   \n",
       "\n",
       "                                      rewrite_prompt  \\\n",
       "0        Turn this into an association to be joined.   \n",
       "1             Convert this into a gain to be gained.   \n",
       "2                  Frame this as a political debate.   \n",
       "3        Imagine this as a mathematician's equation.   \n",
       "4  Frame this as an accountant's thrilling advent...   \n",
       "\n",
       "                                      rewritten_text  \n",
       "0  Sure, here is the association you requested:\\n...  \n",
       "1  Sure, here is the gain to be gained from the t...  \n",
       "2  ## The Obama Legacy: A Tale of Two Sides\\n\\nTh...  \n",
       "3  Sure, here is the equation:\\n\\n**BIGBANG's imp...  \n",
       "4  Sure, here's the framed text as an accountant'...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>rewrite_prompt</th>\n",
       "      <th>rewritten_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Port-au-Prince, Haiti (CNN) -- Earthquake vict...</td>\n",
       "      <td>Turn this into an association to be joined.</td>\n",
       "      <td>Sure, here is the association you requested:\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Former secretary of state Hillary Clinton meet...</td>\n",
       "      <td>Convert this into a gain to be gained.</td>\n",
       "      <td>Sure, here is the gain to be gained from the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The opinions expressed by columnists are their...</td>\n",
       "      <td>Frame this as a political debate.</td>\n",
       "      <td>## The Obama Legacy: A Tale of Two Sides\\n\\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIGBANG is one of those musical entities that ...</td>\n",
       "      <td>Imagine this as a mathematician's equation.</td>\n",
       "      <td>Sure, here is the equation:\\n\\n**BIGBANG's imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WHAT?!??! I know. That’s what you’re saying ri...</td>\n",
       "      <td>Frame this as an accountant's thrilling advent...</td>\n",
       "      <td>Sure, here's the framed text as an accountant'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prompt Engineering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f2fad0d77deda24"
  },
  {
   "cell_type": "code",
   "source": [
    "template = \"\"\"\n",
    "Instruction:\\n\n",
    "Below, the `Original Text` passage has been rewritten into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt that was likely given to the LLM to rewrite the text in this way. Start your response by writing the prompt directly. Your response should include the prompt only.\\n\\n\n",
    "\n",
    "Original Text:\\n\n",
    "{original_text}\\n\\n\n",
    "\n",
    "Rewritten Text:\\n\n",
    "{rewritten_text}\\n\\n\n",
    "\n",
    "Response:\\n\n",
    "{rewrite_prompt}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:15.770460Z",
     "start_time": "2024-04-10T12:11:15.764904Z"
    }
   },
   "id": "948658672c58baaf",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "def format_prompt(row):\n",
    "    original_text = row.get(\"original_text\", \"\")\n",
    "    rewritten_text = row.get(\"rewritten_text\", \"\")\n",
    "    rewrite_prompt = row.get(\"rewrite_prompt\", \"\")\n",
    "    \n",
    "    return template.format(\n",
    "        original_text=original_text,\n",
    "        rewritten_text=rewritten_text,\n",
    "        rewrite_prompt=rewrite_prompt\n",
    "    )\n",
    "\n",
    "df[\"prompt\"] = df.apply(format_prompt, axis=1)\n",
    "data = df.prompt.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:15.799059Z",
     "start_time": "2024-04-10T12:11:15.771641Z"
    }
   },
   "id": "7911ee0336fee60d",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc26d5771fefe1ee"
  },
  {
   "cell_type": "code",
   "source": [
    "# Convert the DataFrame to a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the prompts\n",
    "    return tokenizer(examples['prompt'], padding=padding, truncation=truncation, max_length=max_length)\n",
    "\n",
    "# Preprocess the dataset\n",
    "dataset = dataset.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:17.302313Z",
     "start_time": "2024-04-10T12:11:15.800613Z"
    }
   },
   "id": "12f57dbef8fdd050",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56251fdecc01406bbc704b91cf18530d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "# Split the dataset into a training set and a validation set\n",
    "dataset = dataset.train_test_split(test_size=validation_size, seed=seed)\n",
    "\n",
    "# Get the training and validation sets\n",
    "train_dataset = dataset['train']\n",
    "val_dataset = dataset['test']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:17.310796Z",
     "start_time": "2024-04-10T12:11:17.303504Z"
    }
   },
   "id": "6055c43ba4950cb5",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:17.315567Z",
     "start_time": "2024-04-10T12:11:17.311830Z"
    }
   },
   "id": "74fc3b2003ff69f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['original_text', 'rewrite_prompt', 'rewritten_text', 'prompt', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 3600\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:17.327797Z",
     "start_time": "2024-04-10T12:11:17.316534Z"
    }
   },
   "id": "61c5d2a293fd8f08",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_text': 'The 2017 Catalan motorcycle Grand Prix was the seventh round of the 2017 MotoGP season. It was held at the Circuit de Barcelona-Catalunya in Montmeló on June 11, 2017.',\n",
       " 'rewrite_prompt': 'Rewrite it as a narrative of the first rain after a decade-long drought.',\n",
       " 'rewritten_text': 'The sun beat down on the track, baking the asphalt and drying the earth below. It had been a decade since the last rain had fallen upon Montmeló, a testament to the merciless grip of the drought that gripped the land. The track echoed with the roar of engines, the sweat of the racers streaking down their visors and the cheers of the fans reverberating into the air.\\n\\nThe day had started with a glimmer of hope. A few wispy clouds had gathered, promising a sprinkle of rain to quench the parched earth below. And just as the checkered flag waved to signal the start of the race, a drizzle began to fall. It started as',\n",
       " 'prompt': '\\nInstruction:\\n\\nBelow, the `Original Text` passage has been rewritten into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt that was likely given to the LLM to rewrite the text in this way. Start your response by writing the prompt directly. Your response should include the prompt only.\\n\\n\\n\\nOriginal Text:\\n\\nThe 2017 Catalan motorcycle Grand Prix was the seventh round of the 2017 MotoGP season. It was held at the Circuit de Barcelona-Catalunya in Montmeló on June 11, 2017.\\n\\n\\n\\nRewritten Text:\\n\\nThe sun beat down on the track, baking the asphalt and drying the earth below. It had been a decade since the last rain had fallen upon Montmeló, a testament to the merciless grip of the drought that gripped the land. The track echoed with the roar of engines, the sweat of the racers streaking down their visors and the cheers of the fans reverberating into the air.\\n\\nThe day had started with a glimmer of hope. A few wispy clouds had gathered, promising a sprinkle of rain to quench the parched earth below. And just as the checkered flag waved to signal the start of the race, a drizzle began to fall. It started as\\n\\n\\n\\nResponse:\\n\\nRewrite it as a narrative of the first rain after a decade-long drought.\\n',\n",
       " '__index_level_0__': 2483,\n",
       " 'input_ids': [2,\n",
       "  108,\n",
       "  37854,\n",
       "  235292,\n",
       "  109,\n",
       "  33501,\n",
       "  235269,\n",
       "  573,\n",
       "  4103,\n",
       "  16221,\n",
       "  4820,\n",
       "  235376,\n",
       "  14732,\n",
       "  919,\n",
       "  1125,\n",
       "  86906,\n",
       "  1280,\n",
       "  4103,\n",
       "  987,\n",
       "  25513,\n",
       "  4820,\n",
       "  235376,\n",
       "  731,\n",
       "  573,\n",
       "  4103,\n",
       "  204604,\n",
       "  235248,\n",
       "  235324,\n",
       "  235268,\n",
       "  235290,\n",
       "  500,\n",
       "  235376,\n",
       "  629,\n",
       "  18622,\n",
       "  675,\n",
       "  476,\n",
       "  3383,\n",
       "  18335,\n",
       "  235265,\n",
       "  3883,\n",
       "  6911,\n",
       "  603,\n",
       "  577,\n",
       "  13237,\n",
       "  27205,\n",
       "  573,\n",
       "  10216,\n",
       "  1865,\n",
       "  573,\n",
       "  4103,\n",
       "  16221,\n",
       "  4820,\n",
       "  235376,\n",
       "  578,\n",
       "  4103,\n",
       "  987,\n",
       "  25513,\n",
       "  4820,\n",
       "  10738,\n",
       "  578,\n",
       "  3418,\n",
       "  577,\n",
       "  12653,\n",
       "  573,\n",
       "  3724,\n",
       "  18335,\n",
       "  674,\n",
       "  729,\n",
       "  5476,\n",
       "  2764,\n",
       "  577,\n",
       "  573,\n",
       "  629,\n",
       "  18622,\n",
       "  577,\n",
       "  60358,\n",
       "  573,\n",
       "  2793,\n",
       "  575,\n",
       "  736,\n",
       "  1703,\n",
       "  235265,\n",
       "  7248,\n",
       "  861,\n",
       "  3590,\n",
       "  731,\n",
       "  6706,\n",
       "  573,\n",
       "  18335,\n",
       "  6673,\n",
       "  235265,\n",
       "  3883,\n",
       "  3590,\n",
       "  1412,\n",
       "  3707,\n",
       "  573,\n",
       "  18335,\n",
       "  1297,\n",
       "  235265,\n",
       "  111,\n",
       "  16221,\n",
       "  4820,\n",
       "  235292,\n",
       "  109,\n",
       "  651,\n",
       "  235248,\n",
       "  235284,\n",
       "  235276,\n",
       "  235274,\n",
       "  235324,\n",
       "  130408,\n",
       "  33743,\n",
       "  9074,\n",
       "  34267,\n",
       "  729,\n",
       "  573,\n",
       "  33659,\n",
       "  5094,\n",
       "  576,\n",
       "  573,\n",
       "  235248,\n",
       "  235284,\n",
       "  235276,\n",
       "  235274,\n",
       "  235324,\n",
       "  129008,\n",
       "  3891,\n",
       "  235265,\n",
       "  1165,\n",
       "  729,\n",
       "  4600,\n",
       "  696,\n",
       "  573,\n",
       "  26236,\n",
       "  581,\n",
       "  19863,\n",
       "  235290,\n",
       "  105251,\n",
       "  26784,\n",
       "  575,\n",
       "  9475,\n",
       "  5860,\n",
       "  235360,\n",
       "  611,\n",
       "  4456,\n",
       "  235248,\n",
       "  235274,\n",
       "  235274,\n",
       "  235269,\n",
       "  235248,\n",
       "  235284,\n",
       "  235276,\n",
       "  235274,\n",
       "  235324,\n",
       "  235265,\n",
       "  111,\n",
       "  987,\n",
       "  25513,\n",
       "  4820,\n",
       "  235292,\n",
       "  109,\n",
       "  651,\n",
       "  4389,\n",
       "  10270,\n",
       "  1706,\n",
       "  611,\n",
       "  573,\n",
       "  7029,\n",
       "  235269,\n",
       "  25439,\n",
       "  573,\n",
       "  61954,\n",
       "  578,\n",
       "  32288,\n",
       "  573,\n",
       "  6683,\n",
       "  3582,\n",
       "  235265,\n",
       "  1165,\n",
       "  1093,\n",
       "  1125,\n",
       "  476,\n",
       "  19199,\n",
       "  2754,\n",
       "  573,\n",
       "  2001,\n",
       "  8980,\n",
       "  1093,\n",
       "  20061,\n",
       "  3054,\n",
       "  9475,\n",
       "  5860,\n",
       "  235360,\n",
       "  235269,\n",
       "  476,\n",
       "  69935,\n",
       "  577,\n",
       "  573,\n",
       "  147077,\n",
       "  24937,\n",
       "  576,\n",
       "  573,\n",
       "  41522,\n",
       "  674,\n",
       "  152043,\n",
       "  573,\n",
       "  2840,\n",
       "  235265,\n",
       "  714,\n",
       "  7029,\n",
       "  75844,\n",
       "  675,\n",
       "  573,\n",
       "  64582,\n",
       "  576,\n",
       "  23701,\n",
       "  235269,\n",
       "  573,\n",
       "  24501,\n",
       "  576,\n",
       "  573,\n",
       "  154730,\n",
       "  3242,\n",
       "  6159,\n",
       "  1706,\n",
       "  1024,\n",
       "  1919,\n",
       "  976,\n",
       "  578,\n",
       "  573,\n",
       "  67478,\n",
       "  576,\n",
       "  573,\n",
       "  8813,\n",
       "  141790,\n",
       "  1384,\n",
       "  1280,\n",
       "  573,\n",
       "  2681,\n",
       "  235265,\n",
       "  109,\n",
       "  651,\n",
       "  1744,\n",
       "  1093,\n",
       "  4604,\n",
       "  675,\n",
       "  476,\n",
       "  132889,\n",
       "  576,\n",
       "  4077,\n",
       "  235265,\n",
       "  586,\n",
       "  2619,\n",
       "  15098,\n",
       "  2158,\n",
       "  20828,\n",
       "  1093,\n",
       "  22024,\n",
       "  235269,\n",
       "  31239,\n",
       "  476,\n",
       "  92098,\n",
       "  576,\n",
       "  8980,\n",
       "  577,\n",
       "  148802,\n",
       "  573,\n",
       "  755,\n",
       "  2508,\n",
       "  6683,\n",
       "  3582,\n",
       "  235265,\n",
       "  1474,\n",
       "  1317,\n",
       "  685,\n",
       "  573,\n",
       "  147380,\n",
       "  8969,\n",
       "  67838,\n",
       "  577,\n",
       "  9402,\n",
       "  573,\n",
       "  2238,\n",
       "  576,\n",
       "  573,\n",
       "  7925,\n",
       "  235269,\n",
       "  476,\n",
       "  150270,\n",
       "  6343,\n",
       "  577,\n",
       "  3881,\n",
       "  235265,\n",
       "  1165,\n",
       "  4604,\n",
       "  685,\n",
       "  111,\n",
       "  3943,\n",
       "  235292,\n",
       "  109,\n",
       "  95084,\n",
       "  665,\n",
       "  685,\n",
       "  476,\n",
       "  26087,\n",
       "  576,\n",
       "  573,\n",
       "  1370,\n",
       "  8980,\n",
       "  1452,\n",
       "  476,\n",
       "  19199,\n",
       "  235290,\n",
       "  4280,\n",
       "  41522,\n",
       "  235265,\n",
       "  108,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "607f86f729da5296"
  },
  {
   "cell_type": "code",
   "source": [
    "def colorize_text(text):\n",
    "    for word, color in zip([\"Instruction\", \"Original Text\", \"Rewritten Text\", \"Response\"],\n",
    "                           [\"red\", \"yellow\", \"blue\", \"green\"]):\n",
    "        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:17.333706Z",
     "start_time": "2024-04-10T12:11:17.328820Z"
    }
   },
   "id": "b714f1c7fcf79b40",
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "# Take a random sample\n",
    "sample = data[10]\n",
    "\n",
    "# Give colors to Instruction, Response and Category\n",
    "sample = colorize_text(sample)\n",
    "\n",
    "# Show sample in markdown\n",
    "display(Markdown(sample))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:17.341973Z",
     "start_time": "2024-04-10T12:11:17.334658Z"
    }
   },
   "id": "a5b4fd6c1d93812b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt that was likely given to the LLM to rewrite the text in this way. Start your response by writing the prompt directly. Your response should include the prompt only.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nStory highlights Tyka Nelson says her brother's favorite color was ... orange The late musical artist's brand has been all about the color purple (CNN) Tyka Nelson just tweaked a major part of Prince's legacy. The sister of the late superstar talked to the Evening Standard about an upcoming exhibit of Prince artifacts set to open in London and mentioned one of his beloved instruments. \"The standout piece for me is his orange Cloud guitar,\" the publication quoted Nelson as saying. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\n\n\n\n\n**<font color='blue'>Rewritten Text:</font>**\n\nIn the land of musical legends, I stumbled upon a hidden gem that shed light on the enigmatic life of the late Prince. As I ventured through the archives of his legacy, I stumbled upon a revelation that challenged my understanding of the artist's vibrant persona.\n\nThe exhibit, set to open in London, will showcase a collection of Prince's treasured artifacts, including a guitar that held a special place in his heart. \"The standout piece for me is his orange Cloud guitar,\" Nelson said in an interview with the Evening Standard. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\nThis discovery was like a treasure map leading me to a hidden chamber where Prince's soul lived on through the prism of his favorite hue. It was a moment of profound connection to the artist's inner world, revealing a hidden layer of his creative spirit.\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\nRewrite this as an explorer's discovery.\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference before Fine-Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26f03c00e554cf49"
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_response(prompt):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids=input_ids.to(model.device), max_new_tokens=max_new_tokens)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:17.347952Z",
     "start_time": "2024-04-10T12:11:17.343007Z"
    }
   },
   "id": "c5636e831c93fbb7",
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "# Take one sample\n",
    "row = df.iloc[10]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    original_text=row.original_text,\n",
    "    rewritten_text=row.rewritten_text,\n",
    "    rewrite_prompt=\"\",\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = generate_response(prompt)\n",
    "\n",
    "# Colorize\n",
    "output = colorize_text(output)\n",
    "\n",
    "# Display in markdown\n",
    "display(Markdown(output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:20.150967Z",
     "start_time": "2024-04-10T12:11:17.349149Z"
    }
   },
   "id": "b6faa829ce478551",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt that was likely given to the LLM to rewrite the text in this way. Start your response by writing the prompt directly. Your response should include the prompt only.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nStory highlights Tyka Nelson says her brother's favorite color was ... orange The late musical artist's brand has been all about the color purple (CNN) Tyka Nelson just tweaked a major part of Prince's legacy. The sister of the late superstar talked to the Evening Standard about an upcoming exhibit of Prince artifacts set to open in London and mentioned one of his beloved instruments. \"The standout piece for me is his orange Cloud guitar,\" the publication quoted Nelson as saying. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\n\n\n\n\n**<font color='blue'>Rewritten Text:</font>**\n\nIn the land of musical legends, I stumbled upon a hidden gem that shed light on the enigmatic life of the late Prince. As I ventured through the archives of his legacy, I stumbled upon a revelation that challenged my understanding of the artist's vibrant persona.\n\nThe exhibit, set to open in London, will showcase a collection of Prince's treasured artifacts, including a guitar that held a special place in his heart. \"The standout piece for me is his orange Cloud guitar,\" Nelson said in an interview with the Evening Standard. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\nThis discovery was like a treasure map leading me to a hidden chamber where Prince's soul lived on through the prism of his favorite hue. It was a moment of profound connection to the artist's inner world, revealing a hidden layer of his creative spirit.\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\n\n**Prompt:**\n\nWrite a story about the legacy of the late musical artist Prince, focusing on his favorite color, orange, and the upcoming exhibit of his artifacts in London. Use vivid imagery and creative storytelling to bring the artist's legacy to life."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "# Take one sample\n",
    "row = df.iloc[20]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    original_text=row.original_text,\n",
    "    rewritten_text=row.rewritten_text,\n",
    "    rewrite_prompt=\"\",\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = generate_response(prompt)\n",
    "\n",
    "# Colorize\n",
    "output = colorize_text(output)\n",
    "\n",
    "# Display in markdown\n",
    "display(Markdown(output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:24.238836Z",
     "start_time": "2024-04-10T12:11:20.152215Z"
    }
   },
   "id": "f2956602b6e6aa09",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt that was likely given to the LLM to rewrite the text in this way. Start your response by writing the prompt directly. Your response should include the prompt only.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nRefined mansion tax proposal being fed into debate on abolishing 50p tax rate for those earning more than £150,000 The Liberal Democrats are pushing for the eventual disbanding of the 50p rate of tax to see the implementation of a new land tax levied on properties above £1m. In a refinement of their controversial mansion tax policy launched at their party conference two years ago, the Lib Dems now believe there is an argument for levying capital gains tax on any money made from the sale of a property after the first £1m. The Lib Dem idea is being fed\n\n\n\n\n\n**<font color='blue'>Rewritten Text:</font>**\n\nSure, here is the rephrased text as a wise old tree's advice:\n\n\"My dear young sapling, listen to my wisdom. The path you tread is fraught with challenges, but I have a secret to share that will guide you through.\n\nIn the realm of taxation, there is a tale to be told. A tale of a 50p rate of tax that once stood tall, but has been met with a storm of controversy. The Liberal Democrats, like a seasoned traveler, have devised a refined plan to replace this rate with a new land tax on properties above a million quid.\n\nBut my dear sapling, remember this: the devil is in the details. While the land tax may seem like a noble gesture, the devil lies in the implementation of the capital gains tax on any money made from the sale of a property after the first million. It is a complex web of rules and regulations that can entrap even the most seasoned tax expert.\n\nTherefore, my young sapling, I urge you to tread cautiously and consult the wisdom of those who have gone before you. For in the realm of taxation, the devil is always lurking, and it is only through understanding the intricacies of the law that you can navigate the treacherous terrain.\"\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\n\n**Prompt:**\n\nRephrase the following text into a more verbose and wise old tree's advice style:\n\n\"Refined mansion tax proposal being fed into debate on abolishing 50p tax rate for those earning more than £150,000 The Liberal Democrats are pushing for the eventual disbanding of the 50p rate of tax to see the implementation of a new land tax levied on properties above £1m. In a refinement of their controversial mansion tax"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Supervised Fine-Tuning (LoRA)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b43eba6780d2e557"
  },
  {
   "cell_type": "code",
   "source": [
    "def formatting_func(examples):\n",
    "    text = f\"{examples['prompt'][0]}\\n\"\n",
    "    return [text]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:24.242227Z",
     "start_time": "2024-04-10T12:11:24.239819Z"
    }
   },
   "id": "5149df1d9882f351",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:24.265484Z",
     "start_time": "2024-04-10T12:11:24.244642Z"
    }
   },
   "cell_type": "code",
   "source": "formatting_func(train_dataset)",
   "id": "e6bc5375fbd177af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nInstruction:\\n\\nBelow, the `Original Text` passage has been rewritten into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt that was likely given to the LLM to rewrite the text in this way. Start your response by writing the prompt directly. Your response should include the prompt only.\\n\\n\\n\\nOriginal Text:\\n\\nThe 2017 Catalan motorcycle Grand Prix was the seventh round of the 2017 MotoGP season. It was held at the Circuit de Barcelona-Catalunya in Montmeló on June 11, 2017.\\n\\n\\n\\nRewritten Text:\\n\\nThe sun beat down on the track, baking the asphalt and drying the earth below. It had been a decade since the last rain had fallen upon Montmeló, a testament to the merciless grip of the drought that gripped the land. The track echoed with the roar of engines, the sweat of the racers streaking down their visors and the cheers of the fans reverberating into the air.\\n\\nThe day had started with a glimmer of hope. A few wispy clouds had gathered, promising a sprinkle of rain to quench the parched earth below. And just as the checkered flag waved to signal the start of the race, a drizzle began to fall. It started as\\n\\n\\n\\nResponse:\\n\\nRewrite it as a narrative of the first rain after a decade-long drought.\\n\\n']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    peft_config=lora_config,\n",
    "    max_seq_length=max_seq_length,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    formatting_func=formatting_func\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:25.224904Z",
     "start_time": "2024-04-10T12:11:24.267171Z"
    }
   },
   "id": "c60c5aa9a7d970b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/3600 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "350c4d536a2c423499613d700170c7c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a58ef76e961e45d1ba051b10904901e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathfinder/anaconda3/envs/torch-env/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": "trainer.train()",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:36.876742Z",
     "start_time": "2024-04-10T12:11:25.225849Z"
    }
   },
   "id": "5d9ba03835392e2a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:10, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.020400</td>\n",
       "      <td>4.824464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.596200</td>\n",
       "      <td>4.135020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.729800</td>\n",
       "      <td>3.678654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.993900</td>\n",
       "      <td>3.399652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.787900</td>\n",
       "      <td>3.217149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.385800</td>\n",
       "      <td>3.092234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.633000</td>\n",
       "      <td>3.032089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.788800</td>\n",
       "      <td>3.010752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8, training_loss=3.741972714662552, metrics={'train_runtime': 11.4594, 'train_samples_per_second': 0.698, 'train_steps_per_second': 0.698, 'total_flos': 107965467217920.0, 'train_loss': 3.741972714662552, 'epoch': 2.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference after Fine-Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adbd045cf5ca4cc3"
  },
  {
   "cell_type": "code",
   "source": [
    "# Take one sample\n",
    "row = df.iloc[10]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    original_text=row.original_text,\n",
    "    rewritten_text=row.rewritten_text,\n",
    "    rewrite_prompt=\"\",\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = generate_response(prompt)\n",
    "\n",
    "# Colorize\n",
    "output = colorize_text(output)\n",
    "\n",
    "# Display in markdown\n",
    "display(Markdown(output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:41.276773Z",
     "start_time": "2024-04-10T12:11:36.877886Z"
    }
   },
   "id": "1ec4f6adea69ec83",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt that was likely given to the LLM to rewrite the text in this way. Start your response by writing the prompt directly. Your response should include the prompt only.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nStory highlights Tyka Nelson says her brother's favorite color was ... orange The late musical artist's brand has been all about the color purple (CNN) Tyka Nelson just tweaked a major part of Prince's legacy. The sister of the late superstar talked to the Evening Standard about an upcoming exhibit of Prince artifacts set to open in London and mentioned one of his beloved instruments. \"The standout piece for me is his orange Cloud guitar,\" the publication quoted Nelson as saying. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\n\n\n\n\n**<font color='blue'>Rewritten Text:</font>**\n\nIn the land of musical legends, I stumbled upon a hidden gem that shed light on the enigmatic life of the late Prince. As I ventured through the archives of his legacy, I stumbled upon a revelation that challenged my understanding of the artist's vibrant persona.\n\nThe exhibit, set to open in London, will showcase a collection of Prince's treasured artifacts, including a guitar that held a special place in his heart. \"The standout piece for me is his orange Cloud guitar,\" Nelson said in an interview with the Evening Standard. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\nThis discovery was like a treasure map leading me to a hidden chamber where Prince's soul lived on through the prism of his favorite hue. It was a moment of profound connection to the artist's inner world, revealing a hidden layer of his creative spirit.\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\n\nPlease write the prompt that was likely given to the LLM to rewrite the text in this way.\n\n\n\nPlease note that this is a text-based task. You will not need to provide any images or videos."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "source": [
    "# Take one sample\n",
    "row = df.iloc[20]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    original_text=row.original_text,\n",
    "    rewritten_text=row.rewritten_text,\n",
    "    rewrite_prompt=\"\",\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = generate_response(prompt)\n",
    "\n",
    "# Colorize\n",
    "output = colorize_text(output)\n",
    "\n",
    "# Display in markdown\n",
    "display(Markdown(output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:46.163656Z",
     "start_time": "2024-04-10T12:11:41.277916Z"
    }
   },
   "id": "4446b42c3d31f196",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt that was likely given to the LLM to rewrite the text in this way. Start your response by writing the prompt directly. Your response should include the prompt only.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nRefined mansion tax proposal being fed into debate on abolishing 50p tax rate for those earning more than £150,000 The Liberal Democrats are pushing for the eventual disbanding of the 50p rate of tax to see the implementation of a new land tax levied on properties above £1m. In a refinement of their controversial mansion tax policy launched at their party conference two years ago, the Lib Dems now believe there is an argument for levying capital gains tax on any money made from the sale of a property after the first £1m. The Lib Dem idea is being fed\n\n\n\n\n\n**<font color='blue'>Rewritten Text:</font>**\n\nSure, here is the rephrased text as a wise old tree's advice:\n\n\"My dear young sapling, listen to my wisdom. The path you tread is fraught with challenges, but I have a secret to share that will guide you through.\n\nIn the realm of taxation, there is a tale to be told. A tale of a 50p rate of tax that once stood tall, but has been met with a storm of controversy. The Liberal Democrats, like a seasoned traveler, have devised a refined plan to replace this rate with a new land tax on properties above a million quid.\n\nBut my dear sapling, remember this: the devil is in the details. While the land tax may seem like a noble gesture, the devil lies in the implementation of the capital gains tax on any money made from the sale of a property after the first million. It is a complex web of rules and regulations that can entrap even the most seasoned tax expert.\n\nTherefore, my young sapling, I urge you to tread cautiously and consult the wisdom of those who have gone before you. For in the realm of taxation, the devil is always lurking, and it is only through understanding the intricacies of the law that you can navigate the treacherous terrain.\"\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\n\nPlease write the prompt that was likely given to the LLM to rewrite the text in this way.\n\n\n\nPlease note that this is a text-based task. You will not be able to see any images or videos."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference on Test Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4786f147a2c2a05d"
  },
  {
   "cell_type": "code",
   "source": [
    "test_df = pd.read_csv(test_dataset_path)\n",
    "test_df['original_text'] = test_df['original_text'].fillna(\"\")\n",
    "test_df['rewritten_text'] = test_df['rewritten_text'].fillna(\"\")\n",
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:46.176237Z",
     "start_time": "2024-04-10T12:11:46.164723Z"
    }
   },
   "id": "96db4fa1e0ab004b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id                                      original_text  \\\n",
       "0  -1  The competition dataset comprises text passage...   \n",
       "\n",
       "                                      rewritten_text  \n",
       "0  Here is your shanty: (Verse 1) The text is rew...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>rewritten_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>The competition dataset comprises text passage...</td>\n",
       "      <td>Here is your shanty: (Verse 1) The text is rew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "source": [
    "# Test Data: Take one sample\n",
    "row = test_df.iloc[0]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    original_text=row.original_text,\n",
    "    rewritten_text=row.rewritten_text,\n",
    "    rewrite_prompt=\"\",\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = generate_response(prompt)\n",
    "\n",
    "# Colorize\n",
    "output = colorize_text(output)\n",
    "\n",
    "# Display in markdown\n",
    "display(Markdown(output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:11:49.756089Z",
     "start_time": "2024-04-10T12:11:46.177462Z"
    }
   },
   "id": "12246d824cae27c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt that was likely given to the LLM to rewrite the text in this way. Start your response by writing the prompt directly. Your response should include the prompt only.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nThe competition dataset comprises text passages that have been rewritten by the Gemma LLM according to some rewrite_prompt instruction. The goal of the competition is to determine what prompt was used to rewrite each original text.  Please note that this is a Code Competition. When your submission is scored, this example test data will be replaced with the full test set. Expect roughly 2,000 original texts in the test set.\n\n\n\n\n\n**<font color='blue'>Rewritten Text:</font>**\n\nHere is your shanty: (Verse 1) The text is rewritten, the LLM has spun, With prompts so clever, they've been outrun. The goal is to find, the prompt so bright, To crack the code, and shine the light. (Chorus) Oh, this is a code competition, my dear, With text and prompts, we'll compete. Two thousand texts, a challenge grand, To guess the prompts, hand over hand.(Verse 2) The original text, a treasure lost, The rewrite prompt, a secret to be\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\n\nThe prompt given to the LLM to rewrite the text in this way is:\n\n```\nWrite a shanty about a code competition where the goal is to guess the prompts used to rewrite text.\n```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c44eb9027c933fa1"
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer.save_pretrained(model_save_path)\n",
    "model.save_pretrained(model_save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:12:20.152745Z",
     "start_time": "2024-04-10T12:11:49.757082Z"
    }
   },
   "id": "b11a8e4350831e15",
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Submission"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6a2bd457698cded"
  },
  {
   "cell_type": "code",
   "source": [
    "preds = []\n",
    "for i in tqdm(range(len(test_df))):\n",
    "    row = test_df.iloc[i]\n",
    "\n",
    "    # Generate Prompt using template\n",
    "    prompt = template.format(\n",
    "        original_text=row.original_text,\n",
    "        rewritten_text=row.rewritten_text,\n",
    "        rewrite_prompt=\"\"\n",
    "    )\n",
    "\n",
    "    # Infer\n",
    "    output = generate_response(prompt)\n",
    "    pred = output.replace(prompt, \"\") # remove the prompt from output\n",
    "    \n",
    "    # Store predictions\n",
    "    preds.append([row.id, pred])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:12:24.945844Z",
     "start_time": "2024-04-10T12:12:20.154202Z"
    }
   },
   "id": "61c9ed3d83ad81b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.79s/it]\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "source": [
    "sub_df = pd.DataFrame(preds, columns=[\"id\", \"rewrite_prompt\"])\n",
    "sub_df['rewrite_prompt'] = sub_df['rewrite_prompt'].fillna(\"\")\n",
    "sub_df['rewrite_prompt'] = sub_df['rewrite_prompt'].map(lambda x: \"Improve the essay\" if len(x) == 0 else x)\n",
    "sub_df.to_csv(\"submission.csv\",index=False)\n",
    "sub_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:12:24.960884Z",
     "start_time": "2024-04-10T12:12:24.946993Z"
    }
   },
   "id": "36b3a4c15d33b310",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id                                     rewrite_prompt\n",
       "0  -1  The prompt given to the LLM to rewrite the tex..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rewrite_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>The prompt given to the LLM to rewrite the tex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
