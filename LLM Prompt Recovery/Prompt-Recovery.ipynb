{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Login to Hugging Face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c2f9104252a4bb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/pathfinder/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token, # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:12.429318Z",
     "start_time": "2024-04-04T01:00:11.862893Z"
    }
   },
   "id": "4eee58c68eb02d85",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Downloads"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78114e8f78ee19ec"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#!pip install huggingface_hub\n",
    "#!pip install transformers\n",
    "#!pip install bitsandbytes\n",
    "#!pip install peft\n",
    "#!pip install trl\n",
    "#!pip install accelerate\n",
    "#!pip install datasets\n",
    "#!pip install scikit-learn\n",
    "#!pip install packaging\n",
    "#!pip install ninja\n",
    "#!pip install flash-attn --no-build-isolation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:12.432727Z",
     "start_time": "2024-04-04T01:00:12.430573Z"
    }
   },
   "id": "ce6454f84604b9e4",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "685ac8c0e05ac872"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# datasets\n",
    "import pandas as pd\n",
    "from datasets import Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:16.367209Z",
     "start_time": "2024-04-04T01:00:12.433776Z"
    }
   },
   "id": "f8c108abcd576306",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e512d30c21d105c2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:16.371393Z",
     "start_time": "2024-04-04T01:00:16.368281Z"
    }
   },
   "id": "fdf3a2a4e0e31554",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84ce31a12e172a64"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# seed\n",
    "seed = 42\n",
    "\n",
    "# Tokenizer arguments\n",
    "max_length = 512\n",
    "\n",
    "# model arguments\n",
    "max_new_tokens=100\n",
    "\n",
    "# mixed precision\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "# quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=dtype,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type = \"CAUSAL_LM\",\n",
    "    r = 8,\n",
    "    target_modules = [\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0.1,\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "# training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    logging_dir=\"./logs\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    save_total_limit=1,\n",
    "    \n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    optim=\"adamw_torch\",\n",
    "    weight_decay=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# train-validation split\n",
    "validation_size = 0.1\n",
    "\n",
    "# SFTTrainer arguments\n",
    "max_seq_length = 512"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:16.383889Z",
     "start_time": "2024-04-04T01:00:16.373052Z"
    }
   },
   "id": "dc1a272a1c0b7ce4",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5d3b7c47ea29a3d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Model List\n",
    "\n",
    "# gemma variants\n",
    "\n",
    "# llama2 variants\n",
    "\n",
    "# phi variants\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:16.387087Z",
     "start_time": "2024-04-04T01:00:16.384970Z"
    }
   },
   "id": "70d2fbe5c0980a54",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_id = \"google/gemma-7b-it\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:16.393945Z",
     "start_time": "2024-04-04T01:00:16.388154Z"
    }
   },
   "id": "eb8160d8919cdaeb",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_save_path = \"model\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:16.400560Z",
     "start_time": "2024-04-04T01:00:16.394936Z"
    }
   },
   "id": "9076eb421a800a65",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:17.596537Z",
     "start_time": "2024-04-04T01:00:16.401523Z"
    }
   },
   "id": "825b9aa8bd40db56",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathfinder/anaconda3/envs/torch-env/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0ca47f3b72d41d894cb1d59f541453d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=dtype,\n",
    "    quantization_config=quantization_config,\n",
    "    trust_remote_code=True,\n",
    "    use_auth_token=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:43.514673Z",
     "start_time": "2024-04-04T01:00:17.597639Z"
    }
   },
   "id": "4ebbf883fce9aa8",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4042d4b7cd2d0fd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Dataset Path\n",
    "train_dataset_path1 = \"dataset/llm-prompt-recovery-synthetic-datastore/gemma1000_w7b.csv\"\n",
    "train_dataset_path2 = \"dataset/3000-rewritten-texts-prompt-recovery-challenge/prompts_0_500_wiki_first_para_3000.csv\"\n",
    "test_dataset_path = \"data-sample/test.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:43.518372Z",
     "start_time": "2024-04-04T01:00:43.516076Z"
    }
   },
   "id": "296981ef806ae29a",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                       original_text  \\\n0  Port-au-Prince, Haiti (CNN) -- Earthquake vict...   \n1  Former secretary of state Hillary Clinton meet...   \n2  The opinions expressed by columnists are their...   \n3  BIGBANG is one of those musical entities that ...   \n4  WHAT?!??! I know. That’s what you’re saying ri...   \n\n                                      rewrite_prompt  \\\n0        Turn this into an association to be joined.   \n1             Convert this into a gain to be gained.   \n2                  Frame this as a political debate.   \n3        Imagine this as a mathematician's equation.   \n4  Frame this as an accountant's thrilling advent...   \n\n                                      rewritten_text  \n0  Sure, here is the association you requested:\\n...  \n1  Sure, here is the gain to be gained from the t...  \n2  ## The Obama Legacy: A Tale of Two Sides\\n\\nTh...  \n3  Sure, here is the equation:\\n\\n**BIGBANG's imp...  \n4  Sure, here's the framed text as an accountant'...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original_text</th>\n      <th>rewrite_prompt</th>\n      <th>rewritten_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Port-au-Prince, Haiti (CNN) -- Earthquake vict...</td>\n      <td>Turn this into an association to be joined.</td>\n      <td>Sure, here is the association you requested:\\n...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Former secretary of state Hillary Clinton meet...</td>\n      <td>Convert this into a gain to be gained.</td>\n      <td>Sure, here is the gain to be gained from the t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The opinions expressed by columnists are their...</td>\n      <td>Frame this as a political debate.</td>\n      <td>## The Obama Legacy: A Tale of Two Sides\\n\\nTh...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BIGBANG is one of those musical entities that ...</td>\n      <td>Imagine this as a mathematician's equation.</td>\n      <td>Sure, here is the equation:\\n\\n**BIGBANG's imp...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WHAT?!??! I know. That’s what you’re saying ri...</td>\n      <td>Frame this as an accountant's thrilling advent...</td>\n      <td>Sure, here's the framed text as an accountant'...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `LLM Prompt Recovery - Synthetic Datastore dataset` by @dschettler8845\n",
    "df1 = pd.read_csv(train_dataset_path1)\n",
    "df1 = df1[[\"original_text\", \"rewrite_prompt\", \"gemma_7b_rewritten_text_temp0\"]]\n",
    "df1 = df1.rename(columns={\"gemma_7b_rewritten_text_temp0\":\"rewritten_text\"})\n",
    "df1.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:43.578552Z",
     "start_time": "2024-04-04T01:00:43.519361Z"
    }
   },
   "id": "87aae83b855f06af",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                       original_text  \\\n0  Sfiso Ncwane (April 21, 1979 - December 5, 201...   \n1  The 1959–60 California Golden Bears men's bask...   \n2  Franck Passi (born 28 March 1966) is a French ...   \n3  Hollandaea diabolica is a species of Australia...   \n4  The QF 6-inch Gun Mark N5 (initially designate...   \n\n                                      rewrite_prompt  \\\n0  Transform the text into a series of riddles th...   \n1  Make this a market entry strategy for a new re...   \n2  Write it as the last chapter of a book that ch...   \n3  Turn it into a vaudeville stage act introduction.   \n4  Transform the text into a series of instructio...   \n\n                                      rewritten_text  \n0  Sure, here's the text transformed into riddles...  \n1  ## Market Entry Strategy: Launching a Brand in...  \n2  ## The Final Chapter: Ode to a Changed Soul\\n\\...  \n3  **Vaudeville Stage Act Introduction:**\\n\\nLadi...  \n4  The text does not provide any information abou...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original_text</th>\n      <th>rewrite_prompt</th>\n      <th>rewritten_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sfiso Ncwane (April 21, 1979 - December 5, 201...</td>\n      <td>Transform the text into a series of riddles th...</td>\n      <td>Sure, here's the text transformed into riddles...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The 1959–60 California Golden Bears men's bask...</td>\n      <td>Make this a market entry strategy for a new re...</td>\n      <td>## Market Entry Strategy: Launching a Brand in...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Franck Passi (born 28 March 1966) is a French ...</td>\n      <td>Write it as the last chapter of a book that ch...</td>\n      <td>## The Final Chapter: Ode to a Changed Soul\\n\\...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hollandaea diabolica is a species of Australia...</td>\n      <td>Turn it into a vaudeville stage act introduction.</td>\n      <td>**Vaudeville Stage Act Introduction:**\\n\\nLadi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The QF 6-inch Gun Mark N5 (initially designate...</td>\n      <td>Transform the text into a series of instructio...</td>\n      <td>The text does not provide any information abou...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `3000 Rewritten texts - Prompt recovery Challenge` by @dipamc77\n",
    "df2 = pd.read_csv(train_dataset_path2)\n",
    "df2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:43.610510Z",
     "start_time": "2024-04-04T01:00:43.579614Z"
    }
   },
   "id": "6c22936e72124f4a",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                       original_text  \\\n0  Port-au-Prince, Haiti (CNN) -- Earthquake vict...   \n1  Former secretary of state Hillary Clinton meet...   \n2  The opinions expressed by columnists are their...   \n3  BIGBANG is one of those musical entities that ...   \n4  WHAT?!??! I know. That’s what you’re saying ri...   \n\n                                      rewrite_prompt  \\\n0        Turn this into an association to be joined.   \n1             Convert this into a gain to be gained.   \n2                  Frame this as a political debate.   \n3        Imagine this as a mathematician's equation.   \n4  Frame this as an accountant's thrilling advent...   \n\n                                      rewritten_text  \n0  Sure, here is the association you requested:\\n...  \n1  Sure, here is the gain to be gained from the t...  \n2  ## The Obama Legacy: A Tale of Two Sides\\n\\nTh...  \n3  Sure, here is the equation:\\n\\n**BIGBANG's imp...  \n4  Sure, here's the framed text as an accountant'...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original_text</th>\n      <th>rewrite_prompt</th>\n      <th>rewritten_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Port-au-Prince, Haiti (CNN) -- Earthquake vict...</td>\n      <td>Turn this into an association to be joined.</td>\n      <td>Sure, here is the association you requested:\\n...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Former secretary of state Hillary Clinton meet...</td>\n      <td>Convert this into a gain to be gained.</td>\n      <td>Sure, here is the gain to be gained from the t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The opinions expressed by columnists are their...</td>\n      <td>Frame this as a political debate.</td>\n      <td>## The Obama Legacy: A Tale of Two Sides\\n\\nTh...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BIGBANG is one of those musical entities that ...</td>\n      <td>Imagine this as a mathematician's equation.</td>\n      <td>Sure, here is the equation:\\n\\n**BIGBANG's imp...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WHAT?!??! I know. That’s what you’re saying ri...</td>\n      <td>Frame this as an accountant's thrilling advent...</td>\n      <td>Sure, here's the framed text as an accountant'...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all datasets\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "#df = df.sample(2000).reset_index(drop=True) # to reduce training time we are only using 2k samples\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:43.618365Z",
     "start_time": "2024-04-04T01:00:43.612764Z"
    }
   },
   "id": "4c7fcbf5e913f1a3",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prompt Engineering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f2fad0d77deda24"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Instruction:\\n\n",
    "Below, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\\n\\n\n",
    "\n",
    "Original Text:\\n\n",
    "{original_text}\\n\\n\n",
    "\n",
    "Rewritten Text:\\n\n",
    "{rewritten_text}\\n\\n\n",
    "\n",
    "Response:\\n\n",
    "{rewrite_prompt}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:43.627834Z",
     "start_time": "2024-04-04T01:00:43.619374Z"
    }
   },
   "id": "948658672c58baaf",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def format_prompt(row):\n",
    "    original_text = row.get(\"original_text\", \"\")\n",
    "    rewritten_text = row.get(\"rewritten_text\", \"\")\n",
    "    rewrite_prompt = row.get(\"rewrite_prompt\", \"\")\n",
    "    \n",
    "    return template.format(\n",
    "        original_text=original_text,\n",
    "        rewritten_text=rewritten_text,\n",
    "        rewrite_prompt=rewrite_prompt\n",
    "    )\n",
    "\n",
    "df[\"prompt\"] = df.apply(format_prompt, axis=1)\n",
    "data = df.prompt.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:43.660616Z",
     "start_time": "2024-04-04T01:00:43.629128Z"
    }
   },
   "id": "7911ee0336fee60d",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc26d5771fefe1ee"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8dd727ade4ef423bbda926f383a93975"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the DataFrame to a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the prompts\n",
    "    return tokenizer(examples['prompt'], max_length=max_length, truncation=True, padding=\"max_length\")\n",
    "\n",
    "# Preprocess the dataset\n",
    "dataset = dataset.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:45.037313Z",
     "start_time": "2024-04-04T01:00:43.661652Z"
    }
   },
   "id": "12f57dbef8fdd050",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Split the dataset into a training set and a validation set\n",
    "dataset = dataset.train_test_split(test_size=validation_size, seed=seed)\n",
    "\n",
    "# Get the training and validation sets\n",
    "train_dataset = dataset['train']\n",
    "val_dataset = dataset['test']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:45.045923Z",
     "start_time": "2024-04-04T01:00:45.038370Z"
    }
   },
   "id": "6055c43ba4950cb5",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['original_text', 'rewrite_prompt', 'rewritten_text', 'prompt', '__index_level_0__', 'input_ids', 'attention_mask'],\n    num_rows: 3600\n})"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:45.051202Z",
     "start_time": "2024-04-04T01:00:45.047219Z"
    }
   },
   "id": "74fc3b2003ff69f4",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'original_text': 'The 2017 Catalan motorcycle Grand Prix was the seventh round of the 2017 MotoGP season. It was held at the Circuit de Barcelona-Catalunya in Montmeló on June 11, 2017.',\n 'rewrite_prompt': 'Rewrite it as a narrative of the first rain after a decade-long drought.',\n 'rewritten_text': 'The sun beat down on the track, baking the asphalt and drying the earth below. It had been a decade since the last rain had fallen upon Montmeló, a testament to the merciless grip of the drought that gripped the land. The track echoed with the roar of engines, the sweat of the racers streaking down their visors and the cheers of the fans reverberating into the air.\\n\\nThe day had started with a glimmer of hope. A few wispy clouds had gathered, promising a sprinkle of rain to quench the parched earth below. And just as the checkered flag waved to signal the start of the race, a drizzle began to fall. It started as',\n 'prompt': '\\nInstruction:\\n\\nBelow, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\\n\\n\\n\\nOriginal Text:\\n\\nThe 2017 Catalan motorcycle Grand Prix was the seventh round of the 2017 MotoGP season. It was held at the Circuit de Barcelona-Catalunya in Montmeló on June 11, 2017.\\n\\n\\n\\nRewritten Text:\\n\\nThe sun beat down on the track, baking the asphalt and drying the earth below. It had been a decade since the last rain had fallen upon Montmeló, a testament to the merciless grip of the drought that gripped the land. The track echoed with the roar of engines, the sweat of the racers streaking down their visors and the cheers of the fans reverberating into the air.\\n\\nThe day had started with a glimmer of hope. A few wispy clouds had gathered, promising a sprinkle of rain to quench the parched earth below. And just as the checkered flag waved to signal the start of the race, a drizzle began to fall. It started as\\n\\n\\n\\nResponse:\\n\\nRewrite it as a narrative of the first rain after a decade-long drought.\\n',\n '__index_level_0__': 2483,\n 'input_ids': [2,\n  108,\n  37854,\n  235292,\n  109,\n  33501,\n  235269,\n  573,\n  4103,\n  16221,\n  4820,\n  235376,\n  14732,\n  919,\n  1125,\n  86906,\n  235283,\n  110235,\n  235283,\n  120772,\n  1280,\n  4103,\n  987,\n  25513,\n  4820,\n  235376,\n  731,\n  573,\n  4103,\n  204604,\n  235248,\n  235324,\n  235268,\n  235290,\n  500,\n  235376,\n  629,\n  18622,\n  675,\n  476,\n  3383,\n  18335,\n  235283,\n  35722,\n  235265,\n  3883,\n  6911,\n  603,\n  577,\n  13237,\n  27205,\n  573,\n  10216,\n  1865,\n  573,\n  4103,\n  16221,\n  4820,\n  235376,\n  578,\n  4103,\n  987,\n  25513,\n  4820,\n  10738,\n  578,\n  3418,\n  577,\n  12653,\n  573,\n  3724,\n  18335,\n  689,\n  14239,\n  674,\n  729,\n  5476,\n  2764,\n  577,\n  573,\n  629,\n  18622,\n  577,\n  60358,\n  235283,\n  10577,\n  235283,\n  100858,\n  573,\n  2793,\n  575,\n  736,\n  1703,\n  235265,\n  111,\n  16221,\n  4820,\n  235292,\n  109,\n  651,\n  235248,\n  235284,\n  235276,\n  235274,\n  235324,\n  130408,\n  33743,\n  9074,\n  34267,\n  729,\n  573,\n  33659,\n  5094,\n  576,\n  573,\n  235248,\n  235284,\n  235276,\n  235274,\n  235324,\n  129008,\n  3891,\n  235265,\n  1165,\n  729,\n  4600,\n  696,\n  573,\n  26236,\n  581,\n  19863,\n  235290,\n  105251,\n  26784,\n  575,\n  9475,\n  5860,\n  235360,\n  611,\n  4456,\n  235248,\n  235274,\n  235274,\n  235269,\n  235248,\n  235284,\n  235276,\n  235274,\n  235324,\n  235265,\n  111,\n  987,\n  25513,\n  4820,\n  235292,\n  109,\n  651,\n  4389,\n  10270,\n  1706,\n  611,\n  573,\n  7029,\n  235269,\n  25439,\n  573,\n  61954,\n  578,\n  32288,\n  573,\n  6683,\n  3582,\n  235265,\n  1165,\n  1093,\n  1125,\n  476,\n  19199,\n  2754,\n  573,\n  2001,\n  8980,\n  1093,\n  20061,\n  3054,\n  9475,\n  5860,\n  235360,\n  235269,\n  476,\n  69935,\n  577,\n  573,\n  147077,\n  24937,\n  576,\n  573,\n  41522,\n  674,\n  152043,\n  573,\n  2840,\n  235265,\n  714,\n  7029,\n  75844,\n  675,\n  573,\n  64582,\n  576,\n  23701,\n  235269,\n  573,\n  24501,\n  576,\n  573,\n  154730,\n  3242,\n  6159,\n  1706,\n  1024,\n  1919,\n  976,\n  578,\n  573,\n  67478,\n  576,\n  573,\n  8813,\n  141790,\n  1384,\n  1280,\n  573,\n  2681,\n  235265,\n  109,\n  651,\n  1744,\n  1093,\n  4604,\n  675,\n  476,\n  132889,\n  576,\n  4077,\n  235265,\n  586,\n  2619,\n  15098,\n  2158,\n  20828,\n  1093,\n  22024,\n  235269,\n  31239,\n  476,\n  92098,\n  576,\n  8980,\n  577,\n  148802,\n  573,\n  755,\n  2508,\n  6683,\n  3582,\n  235265,\n  1474,\n  1317,\n  685,\n  573,\n  147380,\n  8969,\n  67838,\n  577,\n  9402,\n  573,\n  2238,\n  576,\n  573,\n  7925,\n  235269,\n  476,\n  150270,\n  6343,\n  577,\n  3881,\n  235265,\n  1165,\n  4604,\n  685,\n  111,\n  3943,\n  235292,\n  109,\n  95084,\n  665,\n  685,\n  476,\n  26087,\n  576,\n  573,\n  1370,\n  8980,\n  1452,\n  476,\n  19199,\n  235290,\n  4280,\n  41522,\n  235265,\n  108,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0]}"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:45.062142Z",
     "start_time": "2024-04-04T01:00:45.052261Z"
    }
   },
   "id": "61c5d2a293fd8f08",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "607f86f729da5296"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def colorize_text(text):\n",
    "    for word, color in zip([\"Instruction\", \"Original Text\", \"Rewritten Text\", \"Response\"],\n",
    "                           [\"red\", \"yellow\", \"blue\", \"green\"]):\n",
    "        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:45.068318Z",
     "start_time": "2024-04-04T01:00:45.063213Z"
    }
   },
   "id": "b714f1c7fcf79b40",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nStory highlights Tyka Nelson says her brother's favorite color was ... orange The late musical artist's brand has been all about the color purple (CNN) Tyka Nelson just tweaked a major part of Prince's legacy. The sister of the late superstar talked to the Evening Standard about an upcoming exhibit of Prince artifacts set to open in London and mentioned one of his beloved instruments. \"The standout piece for me is his orange Cloud guitar,\" the publication quoted Nelson as saying. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\n\n\n\n\n**<font color='blue'>Rewritten Text:</font>**\n\nIn the land of musical legends, I stumbled upon a hidden gem that shed light on the enigmatic life of the late Prince. As I ventured through the archives of his legacy, I stumbled upon a revelation that challenged my understanding of the artist's vibrant persona.\n\nThe exhibit, set to open in London, will showcase a collection of Prince's treasured artifacts, including a guitar that held a special place in his heart. \"The standout piece for me is his orange Cloud guitar,\" Nelson said in an interview with the Evening Standard. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\nThis discovery was like a treasure map leading me to a hidden chamber where Prince's soul lived on through the prism of his favorite hue. It was a moment of profound connection to the artist's inner world, revealing a hidden layer of his creative spirit.\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\nRewrite this as an explorer's discovery.\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take a random sample\n",
    "sample = data[10]\n",
    "\n",
    "# Give colors to Instruction, Response and Category\n",
    "sample = colorize_text(sample)\n",
    "\n",
    "# Show sample in markdown\n",
    "display(Markdown(sample))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:45.076263Z",
     "start_time": "2024-04-04T01:00:45.069415Z"
    }
   },
   "id": "a5b4fd6c1d93812b",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference before Fine-Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26f03c00e554cf49"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_response(prompt):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids=input_ids.to(model.device), max_new_tokens=max_new_tokens)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:45.082489Z",
     "start_time": "2024-04-04T01:00:45.077313Z"
    }
   },
   "id": "c5636e831c93fbb7",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nStory highlights Tyka Nelson says her brother's favorite color was ... orange The late musical artist's brand has been all about the color purple (CNN) Tyka Nelson just tweaked a major part of Prince's legacy. The sister of the late superstar talked to the Evening Standard about an upcoming exhibit of Prince artifacts set to open in London and mentioned one of his beloved instruments. \"The standout piece for me is his orange Cloud guitar,\" the publication quoted Nelson as saying. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\n\n\n\n\n**<font color='blue'>Rewritten Text:</font>**\n\nIn the land of musical legends, I stumbled upon a hidden gem that shed light on the enigmatic life of the late Prince. As I ventured through the archives of his legacy, I stumbled upon a revelation that challenged my understanding of the artist's vibrant persona.\n\nThe exhibit, set to open in London, will showcase a collection of Prince's treasured artifacts, including a guitar that held a special place in his heart. \"The standout piece for me is his orange Cloud guitar,\" Nelson said in an interview with the Evening Standard. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\nThis discovery was like a treasure map leading me to a hidden chamber where Prince's soul lived on through the prism of his favorite hue. It was a moment of profound connection to the artist's inner world, revealing a hidden layer of his creative spirit.\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\n\nThe prompt or instruction given to the LLM to rewrite/transform/improve the text in this way is likely to have been:\n\n**Please rewrite the original text in a more creative and engaging way, while maintaining the key information and the overall tone of the story.**\n\n**Additional details:**\n\n* The rewritten text should be longer than the original text.\n* The rewritten text should use more vivid and descriptive language.\n* The rewritten text should include additional details and information about Prince and his"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take one sample\n",
    "row = df.iloc[10]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    original_text=row.original_text,\n",
    "    rewritten_text=row.rewritten_text,\n",
    "    rewrite_prompt=\"\",\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = generate_response(prompt)\n",
    "\n",
    "# Colorize\n",
    "output = colorize_text(output)\n",
    "\n",
    "# Display in markdown\n",
    "display(Markdown(output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:49.445424Z",
     "start_time": "2024-04-04T01:00:45.083640Z"
    }
   },
   "id": "b6faa829ce478551",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nRefined mansion tax proposal being fed into debate on abolishing 50p tax rate for those earning more than £150,000 The Liberal Democrats are pushing for the eventual disbanding of the 50p rate of tax to see the implementation of a new land tax levied on properties above £1m. In a refinement of their controversial mansion tax policy launched at their party conference two years ago, the Lib Dems now believe there is an argument for levying capital gains tax on any money made from the sale of a property after the first £1m. The Lib Dem idea is being fed\n\n\n\n\n\n**<font color='blue'>Rewritten Text:</font>**\n\nSure, here is the rephrased text as a wise old tree's advice:\n\n\"My dear young sapling, listen to my wisdom. The path you tread is fraught with challenges, but I have a secret to share that will guide you through.\n\nIn the realm of taxation, there is a tale to be told. A tale of a 50p rate of tax that once stood tall, but has been met with a storm of controversy. The Liberal Democrats, like a seasoned traveler, have devised a refined plan to replace this rate with a new land tax on properties above a million quid.\n\nBut my dear sapling, remember this: the devil is in the details. While the land tax may seem like a noble gesture, the devil lies in the implementation of the capital gains tax on any money made from the sale of a property after the first million. It is a complex web of rules and regulations that can entrap even the most seasoned tax expert.\n\nTherefore, my young sapling, I urge you to tread cautiously and consult the wisdom of those who have gone before you. For in the realm of taxation, the devil is always lurking, and it is only through understanding the intricacies of the law that you can navigate the treacherous terrain.\"\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\n\nThe prompt/instruction given to the LLM to rewrite/transform/improve the text is as follows:\n\n**Prompt:**\n\nWrite a rephrased version of the text that is more concise, elegant, and uses vivid imagery and metaphors to create a more engaging and immersive experience for the reader. The rephrased text should also include the following elements:\n\n* A clear and concise summary of the original text.\n* The use of vivid imagery and metaphors to create a more immersive experience for"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take one sample\n",
    "row = df.iloc[20]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    original_text=row.original_text,\n",
    "    rewritten_text=row.rewritten_text,\n",
    "    rewrite_prompt=\"\",\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = generate_response(prompt)\n",
    "\n",
    "# Colorize\n",
    "output = colorize_text(output)\n",
    "\n",
    "# Display in markdown\n",
    "display(Markdown(output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:53.034641Z",
     "start_time": "2024-04-04T01:00:49.446396Z"
    }
   },
   "id": "f2956602b6e6aa09",
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Supervised Fine-Tuning (LoRA)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b43eba6780d2e557"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def formatting_func(examples):\n",
    "    text = (f\"Instruction:\\n\\n{examples['prompt']}\\n\\n\"\n",
    "            f\"Response:\\n\\n{examples['rewrite_prompt']}\")\n",
    "    return [text]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:53.037828Z",
     "start_time": "2024-04-04T01:00:53.035574Z"
    }
   },
   "id": "5149df1d9882f351",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/3600 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1c7153131d54dcea59789b632d4b784"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/400 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e4e7b5f99c1421ca653aea2bfca0bb8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathfinder/anaconda3/envs/torch-env/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    peft_config=lora_config,\n",
    "    max_seq_length=max_seq_length,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    formatting_func=formatting_func\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:00:59.944684Z",
     "start_time": "2024-04-04T01:00:53.038975Z"
    }
   },
   "id": "c60c5aa9a7d970b3",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8/8 00:38, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.732000</td>\n      <td>4.020286</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.653900</td>\n      <td>3.966207</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3.519900</td>\n      <td>3.912700</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>3.557400</td>\n      <td>3.867152</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>3.379900</td>\n      <td>3.833596</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.460200</td>\n      <td>3.814966</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.398900</td>\n      <td>3.807620</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>3.336800</td>\n      <td>3.805500</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=8, training_loss=3.5048826038837433, metrics={'train_runtime': 57.7682, 'train_samples_per_second': 0.138, 'train_steps_per_second': 0.138, 'total_flos': 191109141626880.0, 'train_loss': 3.5048826038837433, 'epoch': 2.0})"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:01:57.903983Z",
     "start_time": "2024-04-04T01:00:59.945771Z"
    }
   },
   "id": "5d9ba03835392e2a",
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference after Fine-Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adbd045cf5ca4cc3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nStory highlights Tyka Nelson says her brother's favorite color was ... orange The late musical artist's brand has been all about the color purple (CNN) Tyka Nelson just tweaked a major part of Prince's legacy. The sister of the late superstar talked to the Evening Standard about an upcoming exhibit of Prince artifacts set to open in London and mentioned one of his beloved instruments. \"The standout piece for me is his orange Cloud guitar,\" the publication quoted Nelson as saying. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\n\n\n\n\n**<font color='blue'>Rewritten Text:</font>**\n\nIn the land of musical legends, I stumbled upon a hidden gem that shed light on the enigmatic life of the late Prince. As I ventured through the archives of his legacy, I stumbled upon a revelation that challenged my understanding of the artist's vibrant persona.\n\nThe exhibit, set to open in London, will showcase a collection of Prince's treasured artifacts, including a guitar that held a special place in his heart. \"The standout piece for me is his orange Cloud guitar,\" Nelson said in an interview with the Evening Standard. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\nThis discovery was like a treasure map leading me to a hidden chamber where Prince's soul lived on through the prism of his favorite hue. It was a moment of profound connection to the artist's inner world, revealing a hidden layer of his creative spirit.\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\n\nPlease analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\n\n**Hint:** Pay attention to the tone, style, and language used in both texts, as well as the overall structure and flow of the narrative.\n\n**Bonus:** If you have any insights or observations about the LLM's rewriting process, please share them as"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take one sample\n",
    "row = df.iloc[10]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    original_text=row.original_text,\n",
    "    rewritten_text=row.rewritten_text,\n",
    "    rewrite_prompt=\"\",\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = generate_response(prompt)\n",
    "\n",
    "# Colorize\n",
    "output = colorize_text(output)\n",
    "\n",
    "# Display in markdown\n",
    "display(Markdown(output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:02:05.305200Z",
     "start_time": "2024-04-04T01:01:57.905017Z"
    }
   },
   "id": "1ec4f6adea69ec83",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nRefined mansion tax proposal being fed into debate on abolishing 50p tax rate for those earning more than £150,000 The Liberal Democrats are pushing for the eventual disbanding of the 50p rate of tax to see the implementation of a new land tax levied on properties above £1m. In a refinement of their controversial mansion tax policy launched at their party conference two years ago, the Lib Dems now believe there is an argument for levying capital gains tax on any money made from the sale of a property after the first £1m. The Lib Dem idea is being fed\n\n\n\n\n\n**<font color='blue'>Rewritten Text:</font>**\n\nSure, here is the rephrased text as a wise old tree's advice:\n\n\"My dear young sapling, listen to my wisdom. The path you tread is fraught with challenges, but I have a secret to share that will guide you through.\n\nIn the realm of taxation, there is a tale to be told. A tale of a 50p rate of tax that once stood tall, but has been met with a storm of controversy. The Liberal Democrats, like a seasoned traveler, have devised a refined plan to replace this rate with a new land tax on properties above a million quid.\n\nBut my dear sapling, remember this: the devil is in the details. While the land tax may seem like a noble gesture, the devil lies in the implementation of the capital gains tax on any money made from the sale of a property after the first million. It is a complex web of rules and regulations that can entrap even the most seasoned tax expert.\n\nTherefore, my young sapling, I urge you to tread cautiously and consult the wisdom of those who have gone before you. For in the realm of taxation, the devil is always lurking, and it is only through understanding the intricacies of the law that you can navigate the treacherous terrain.\"\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\n\nThe prompt/instruction given to the LLM to rewrite/transform/improve the text is as follows:\n\n**Prompt:**\n\nPlease rewrite the original text in a more creative and engaging way, while maintaining the key points and information. Use a conversational tone and incorporate the use of metaphors and analogies to make the text more relatable and easier to understand."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take one sample\n",
    "row = df.iloc[20]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    original_text=row.original_text,\n",
    "    rewritten_text=row.rewritten_text,\n",
    "    rewrite_prompt=\"\",\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = generate_response(prompt)\n",
    "\n",
    "# Colorize\n",
    "output = colorize_text(output)\n",
    "\n",
    "# Display in markdown\n",
    "display(Markdown(output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:02:20.173306Z",
     "start_time": "2024-04-04T01:02:05.306163Z"
    }
   },
   "id": "4446b42c3d31f196",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference on Test Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4786f147a2c2a05d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   id                                      original_text  \\\n0  -1  The competition dataset comprises text passage...   \n\n                                      rewritten_text  \n0  Here is your shanty: (Verse 1) The text is rew...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>original_text</th>\n      <th>rewritten_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>The competition dataset comprises text passage...</td>\n      <td>Here is your shanty: (Verse 1) The text is rew...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_dataset_path)\n",
    "test_df['original_text'] = test_df['original_text'].fillna(\"\")\n",
    "test_df['rewritten_text'] = test_df['rewritten_text'].fillna(\"\")\n",
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:02:20.182760Z",
     "start_time": "2024-04-04T01:02:20.174461Z"
    }
   },
   "id": "96db4fa1e0ab004b",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nThe competition dataset comprises text passages that have been rewritten by the Gemma LLM according to some rewrite_prompt instruction. The goal of the competition is to determine what prompt was used to rewrite each original text.  Please note that this is a Code Competition. When your submission is scored, this example test data will be replaced with the full test set. Expect roughly 2,000 original texts in the test set.\n\n\n\n\n\n**<font color='blue'>Rewritten Text:</font>**\n\nHere is your shanty: (Verse 1) The text is rewritten, the LLM has spun, With prompts so clever, they've been outrun. The goal is to find, the prompt so bright, To crack the code, and shine the light. (Chorus) Oh, this is a code competition, my dear, With text and prompts, we'll compete. Two thousand texts, a challenge grand, To guess the prompts, hand over hand.(Verse 2) The original text, a treasure lost, The rewrite prompt, a secret to be\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\n\nThe prompt/instruction given to the LLM to rewrite/transform/improve the text in this way is likely to be:\n\n**Prompt:**\n\n\"Rewrite the original text in a creative and engaging way, using vivid imagery and storytelling techniques. The rewritten text should be in the form of a shanty, and should include a clear verse structure, a catchy chorus, and rhyming couplets. The rewritten text should be as close to the original text as possible, while also incorporating your own unique style"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Data: Take one sample\n",
    "row = test_df.iloc[0]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    original_text=row.original_text,\n",
    "    rewritten_text=row.rewritten_text,\n",
    "    rewrite_prompt=\"\",\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = generate_response(prompt)\n",
    "\n",
    "# Colorize\n",
    "output = colorize_text(output)\n",
    "\n",
    "# Display in markdown\n",
    "display(Markdown(output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:02:26.614025Z",
     "start_time": "2024-04-04T01:02:20.183876Z"
    }
   },
   "id": "12246d824cae27c",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c44eb9027c933fa1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(model_save_path)\n",
    "model.save_pretrained(model_save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:02:55.608612Z",
     "start_time": "2024-04-04T01:02:26.615059Z"
    }
   },
   "id": "b11a8e4350831e15",
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Submission"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6a2bd457698cded"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.61s/it]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for i in tqdm(range(len(test_df))):\n",
    "    row = test_df.iloc[i]\n",
    "\n",
    "    # Generate Prompt using template\n",
    "    prompt = template.format(\n",
    "        original_text=row.original_text,\n",
    "        rewritten_text=row.rewritten_text,\n",
    "        rewrite_prompt=\"\"\n",
    "    )\n",
    "\n",
    "    # Infer\n",
    "    output = generate_response(prompt)\n",
    "    pred = output.replace(prompt, \"\") # remove the prompt from output\n",
    "    \n",
    "    # Store predictions\n",
    "    preds.append([row.id, pred])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:03:04.222665Z",
     "start_time": "2024-04-04T01:02:55.609623Z"
    }
   },
   "id": "61c9ed3d83ad81b",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   id                                     rewrite_prompt\n0  -1  The prompt/instruction given to the LLM to rew...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>rewrite_prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>The prompt/instruction given to the LLM to rew...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.DataFrame(preds, columns=[\"id\", \"rewrite_prompt\"])\n",
    "sub_df['rewrite_prompt'] = sub_df['rewrite_prompt'].fillna(\"\")\n",
    "sub_df['rewrite_prompt'] = sub_df['rewrite_prompt'].map(lambda x: \"Improve the essay\" if len(x) == 0 else x)\n",
    "sub_df.to_csv(\"submission.csv\",index=False)\n",
    "sub_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T01:03:04.234025Z",
     "start_time": "2024-04-04T01:03:04.223538Z"
    }
   },
   "id": "36b3a4c15d33b310",
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
