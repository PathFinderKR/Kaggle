{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Login to Hugging Face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c2f9104252a4bb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/pathfinder/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token, # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:04.933117Z",
     "start_time": "2024-04-02T08:05:04.482679Z"
    }
   },
   "id": "4eee58c68eb02d85",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# local\n",
    "output_dir = \"./results\" # ADD YOUR OUTPUT DIRECTORY HERE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:04.936448Z",
     "start_time": "2024-04-02T08:05:04.934255Z"
    }
   },
   "id": "1a601448404de57",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Downloads"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78114e8f78ee19ec"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#!pip install huggingface_hub\n",
    "#!pip install transformers\n",
    "#!pip install bitsandbytes\n",
    "#!pip install peft\n",
    "#!pip install trl\n",
    "#!pip install accelerate\n",
    "#!pip install datasets\n",
    "#!pip install scikit-learn\n",
    "#!pip install packaging\n",
    "#!pip install ninja\n",
    "#!pip install flash-attn --no-build-isolation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:04.943530Z",
     "start_time": "2024-04-02T08:05:04.937422Z"
    }
   },
   "id": "ce6454f84604b9e4",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "685ac8c0e05ac872"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# datasets\n",
    "import pandas as pd\n",
    "from datasets import Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:07.634366Z",
     "start_time": "2024-04-02T08:05:04.945192Z"
    }
   },
   "id": "f8c108abcd576306",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e512d30c21d105c2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:07.638588Z",
     "start_time": "2024-04-02T08:05:07.635566Z"
    }
   },
   "id": "fdf3a2a4e0e31554",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84ce31a12e172a64"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# seed\n",
    "seed = 42\n",
    "\n",
    "# Tokenizer arguments\n",
    "max_length = 512\n",
    "\n",
    "# model arguments\n",
    "max_new_tokens=500\n",
    "\n",
    "# mixed precision\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "# quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=dtype,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type = \"CAUSAL_LM\",\n",
    "    r = 8,\n",
    "    target_modules = [\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0.1,\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "# training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    save_total_limit=1,\n",
    "    \n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"adamw_torch\",\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "    warmup_steps=100,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# train-validation split\n",
    "validation_size = 0.1\n",
    "\n",
    "# SFTTrainer arguments\n",
    "max_seq_length = 512"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:07.652046Z",
     "start_time": "2024-04-02T08:05:07.639800Z"
    }
   },
   "id": "dc1a272a1c0b7ce4",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5d3b7c47ea29a3d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Model List\n",
    "\n",
    "# gemma variants\n",
    "\n",
    "# llama2 variants\n",
    "\n",
    "# phi variants\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:07.655912Z",
     "start_time": "2024-04-02T08:05:07.653456Z"
    }
   },
   "id": "70d2fbe5c0980a54",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_id = \"google/gemma-7b-it\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:07.662913Z",
     "start_time": "2024-04-02T08:05:07.657081Z"
    }
   },
   "id": "eb8160d8919cdaeb",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87703110e5a949669e03e9419aa0ee97"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=dtype,\n",
    "    quantization_config=quantization_config\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:34.565484Z",
     "start_time": "2024-04-02T08:05:07.664144Z"
    }
   },
   "id": "4ebbf883fce9aa8",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4042d4b7cd2d0fd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Dataset Path\n",
    "train_dataset_path1 = \"dataset/llm-prompt-recovery-synthetic-datastore/gemma1000_w7b.csv\"\n",
    "train_dataset_path2 = \"dataset/3000-rewritten-texts-prompt-recovery-challenge/prompts_0_500_wiki_first_para_3000.csv\"\n",
    "test_dataset_path = \"data-sample/test.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:34.569527Z",
     "start_time": "2024-04-02T08:05:34.567199Z"
    }
   },
   "id": "296981ef806ae29a",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                       original_text  \\\n0  Port-au-Prince, Haiti (CNN) -- Earthquake vict...   \n1  Former secretary of state Hillary Clinton meet...   \n2  The opinions expressed by columnists are their...   \n3  BIGBANG is one of those musical entities that ...   \n4  WHAT?!??! I know. That’s what you’re saying ri...   \n\n                                      rewrite_prompt  \\\n0        Turn this into an association to be joined.   \n1             Convert this into a gain to be gained.   \n2                  Frame this as a political debate.   \n3        Imagine this as a mathematician's equation.   \n4  Frame this as an accountant's thrilling advent...   \n\n                                      rewritten_text  \n0  Sure, here is the association you requested:\\n...  \n1  Sure, here is the gain to be gained from the t...  \n2  ## The Obama Legacy: A Tale of Two Sides\\n\\nTh...  \n3  Sure, here is the equation:\\n\\n**BIGBANG's imp...  \n4  Sure, here's the framed text as an accountant'...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original_text</th>\n      <th>rewrite_prompt</th>\n      <th>rewritten_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Port-au-Prince, Haiti (CNN) -- Earthquake vict...</td>\n      <td>Turn this into an association to be joined.</td>\n      <td>Sure, here is the association you requested:\\n...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Former secretary of state Hillary Clinton meet...</td>\n      <td>Convert this into a gain to be gained.</td>\n      <td>Sure, here is the gain to be gained from the t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The opinions expressed by columnists are their...</td>\n      <td>Frame this as a political debate.</td>\n      <td>## The Obama Legacy: A Tale of Two Sides\\n\\nTh...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BIGBANG is one of those musical entities that ...</td>\n      <td>Imagine this as a mathematician's equation.</td>\n      <td>Sure, here is the equation:\\n\\n**BIGBANG's imp...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WHAT?!??! I know. That’s what you’re saying ri...</td>\n      <td>Frame this as an accountant's thrilling advent...</td>\n      <td>Sure, here's the framed text as an accountant'...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `LLM Prompt Recovery - Synthetic Datastore dataset` by @dschettler8845\n",
    "df1 = pd.read_csv(train_dataset_path1)\n",
    "df1 = df1[[\"original_text\", \"rewrite_prompt\", \"gemma_7b_rewritten_text_temp0\"]]\n",
    "df1 = df1.rename(columns={\"gemma_7b_rewritten_text_temp0\":\"rewritten_text\"})\n",
    "df1.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:34.648435Z",
     "start_time": "2024-04-02T08:05:34.571104Z"
    }
   },
   "id": "87aae83b855f06af",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                       original_text  \\\n0  Sfiso Ncwane (April 21, 1979 - December 5, 201...   \n1  The 1959–60 California Golden Bears men's bask...   \n2  Franck Passi (born 28 March 1966) is a French ...   \n3  Hollandaea diabolica is a species of Australia...   \n4  The QF 6-inch Gun Mark N5 (initially designate...   \n\n                                      rewrite_prompt  \\\n0  Transform the text into a series of riddles th...   \n1  Make this a market entry strategy for a new re...   \n2  Write it as the last chapter of a book that ch...   \n3  Turn it into a vaudeville stage act introduction.   \n4  Transform the text into a series of instructio...   \n\n                                      rewritten_text  \n0  Sure, here's the text transformed into riddles...  \n1  ## Market Entry Strategy: Launching a Brand in...  \n2  ## The Final Chapter: Ode to a Changed Soul\\n\\...  \n3  **Vaudeville Stage Act Introduction:**\\n\\nLadi...  \n4  The text does not provide any information abou...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original_text</th>\n      <th>rewrite_prompt</th>\n      <th>rewritten_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sfiso Ncwane (April 21, 1979 - December 5, 201...</td>\n      <td>Transform the text into a series of riddles th...</td>\n      <td>Sure, here's the text transformed into riddles...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The 1959–60 California Golden Bears men's bask...</td>\n      <td>Make this a market entry strategy for a new re...</td>\n      <td>## Market Entry Strategy: Launching a Brand in...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Franck Passi (born 28 March 1966) is a French ...</td>\n      <td>Write it as the last chapter of a book that ch...</td>\n      <td>## The Final Chapter: Ode to a Changed Soul\\n\\...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hollandaea diabolica is a species of Australia...</td>\n      <td>Turn it into a vaudeville stage act introduction.</td>\n      <td>**Vaudeville Stage Act Introduction:**\\n\\nLadi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The QF 6-inch Gun Mark N5 (initially designate...</td>\n      <td>Transform the text into a series of instructio...</td>\n      <td>The text does not provide any information abou...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `3000 Rewritten texts - Prompt recovery Challenge` by @dipamc77\n",
    "df2 = pd.read_csv(train_dataset_path2)\n",
    "df2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:34.695398Z",
     "start_time": "2024-04-02T08:05:34.649524Z"
    }
   },
   "id": "6c22936e72124f4a",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                       original_text  \\\n0  Port-au-Prince, Haiti (CNN) -- Earthquake vict...   \n1  Former secretary of state Hillary Clinton meet...   \n2  The opinions expressed by columnists are their...   \n3  BIGBANG is one of those musical entities that ...   \n4  WHAT?!??! I know. That’s what you’re saying ri...   \n\n                                      rewrite_prompt  \\\n0        Turn this into an association to be joined.   \n1             Convert this into a gain to be gained.   \n2                  Frame this as a political debate.   \n3        Imagine this as a mathematician's equation.   \n4  Frame this as an accountant's thrilling advent...   \n\n                                      rewritten_text  \n0  Sure, here is the association you requested:\\n...  \n1  Sure, here is the gain to be gained from the t...  \n2  ## The Obama Legacy: A Tale of Two Sides\\n\\nTh...  \n3  Sure, here is the equation:\\n\\n**BIGBANG's imp...  \n4  Sure, here's the framed text as an accountant'...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original_text</th>\n      <th>rewrite_prompt</th>\n      <th>rewritten_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Port-au-Prince, Haiti (CNN) -- Earthquake vict...</td>\n      <td>Turn this into an association to be joined.</td>\n      <td>Sure, here is the association you requested:\\n...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Former secretary of state Hillary Clinton meet...</td>\n      <td>Convert this into a gain to be gained.</td>\n      <td>Sure, here is the gain to be gained from the t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The opinions expressed by columnists are their...</td>\n      <td>Frame this as a political debate.</td>\n      <td>## The Obama Legacy: A Tale of Two Sides\\n\\nTh...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BIGBANG is one of those musical entities that ...</td>\n      <td>Imagine this as a mathematician's equation.</td>\n      <td>Sure, here is the equation:\\n\\n**BIGBANG's imp...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WHAT?!??! I know. That’s what you’re saying ri...</td>\n      <td>Frame this as an accountant's thrilling advent...</td>\n      <td>Sure, here's the framed text as an accountant'...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all datasets\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "#df = df.sample(2000).reset_index(drop=True) # to reduce training time we are only using 2k samples\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:34.703138Z",
     "start_time": "2024-04-02T08:05:34.696967Z"
    }
   },
   "id": "4c7fcbf5e913f1a3",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prompt Engineering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f2fad0d77deda24"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Instruction:\\n\n",
    "Below, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\\n\\n\n",
    "\n",
    "Original Text:\\n\n",
    "{original_text}\\n\\n\n",
    "\n",
    "Rewriten Text:\\n\n",
    "{rewritten_text}\\n\\n\n",
    "\n",
    "Response:\\n\n",
    "{rewrite_prompt}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:34.709099Z",
     "start_time": "2024-04-02T08:05:34.704249Z"
    }
   },
   "id": "948658672c58baaf",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def format_prompt(row):\n",
    "    original_text = row.get(\"original_text\", \"\")\n",
    "    rewritten_text = row.get(\"rewritten_text\", \"\")\n",
    "    rewrite_prompt = row.get(\"rewrite_prompt\", \"\")\n",
    "    \n",
    "    return template.format(\n",
    "        original_text=original_text,\n",
    "        rewritten_text=rewritten_text,\n",
    "        rewrite_prompt=rewrite_prompt\n",
    "    )\n",
    "\n",
    "df[\"prompt\"] = df.apply(format_prompt, axis=1)\n",
    "data = df.prompt.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:34.739650Z",
     "start_time": "2024-04-02T08:05:34.710474Z"
    }
   },
   "id": "7911ee0336fee60d",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc26d5771fefe1ee"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9c97777b27c45f0a6702ee6b6c98553"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the DataFrame to a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the prompts\n",
    "    return tokenizer(examples['prompt'], max_length=max_length, truncation=True, padding=\"max_length\")\n",
    "\n",
    "# Preprocess the dataset\n",
    "dataset = dataset.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:36.205515Z",
     "start_time": "2024-04-02T08:05:34.740703Z"
    }
   },
   "id": "12f57dbef8fdd050",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Split the dataset into a training set and a validation set\n",
    "dataset = dataset.train_test_split(test_size=validation_size, seed=seed)\n",
    "\n",
    "# Get the training and validation sets\n",
    "train_dataset = dataset['train']\n",
    "val_dataset = dataset['test']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:36.213062Z",
     "start_time": "2024-04-02T08:05:36.206563Z"
    }
   },
   "id": "6055c43ba4950cb5",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "607f86f729da5296"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def colorize_text(text):\n",
    "    for word, color in zip([\"Instruction\", \"Original Text\", \"Rewriten Text\", \"Response\"],\n",
    "                           [\"red\", \"yellow\", \"blue\", \"green\"]):\n",
    "        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:36.218010Z",
     "start_time": "2024-04-02T08:05:36.214090Z"
    }
   },
   "id": "b714f1c7fcf79b40",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nStory highlights Tyka Nelson says her brother's favorite color was ... orange The late musical artist's brand has been all about the color purple (CNN) Tyka Nelson just tweaked a major part of Prince's legacy. The sister of the late superstar talked to the Evening Standard about an upcoming exhibit of Prince artifacts set to open in London and mentioned one of his beloved instruments. \"The standout piece for me is his orange Cloud guitar,\" the publication quoted Nelson as saying. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\n\n\n\n\n**<font color='blue'>Rewriten Text:</font>**\n\nIn the land of musical legends, I stumbled upon a hidden gem that shed light on the enigmatic life of the late Prince. As I ventured through the archives of his legacy, I stumbled upon a revelation that challenged my understanding of the artist's vibrant persona.\n\nThe exhibit, set to open in London, will showcase a collection of Prince's treasured artifacts, including a guitar that held a special place in his heart. \"The standout piece for me is his orange Cloud guitar,\" Nelson said in an interview with the Evening Standard. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\nThis discovery was like a treasure map leading me to a hidden chamber where Prince's soul lived on through the prism of his favorite hue. It was a moment of profound connection to the artist's inner world, revealing a hidden layer of his creative spirit.\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\nRewrite this as an explorer's discovery.\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take a random sample\n",
    "sample = data[10]\n",
    "\n",
    "# Give colors to Instruction, Response and Category\n",
    "sample = colorize_text(sample)\n",
    "\n",
    "# Show sample in markdown\n",
    "display(Markdown(sample))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:36.226266Z",
     "start_time": "2024-04-02T08:05:36.218943Z"
    }
   },
   "id": "a5b4fd6c1d93812b",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference before Fine-Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26f03c00e554cf49"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_response(prompt):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids=input_ids.to(model.device), max_new_tokens=max_new_tokens)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:36.232457Z",
     "start_time": "2024-04-02T08:05:36.227313Z"
    }
   },
   "id": "c5636e831c93fbb7",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nStory highlights Tyka Nelson says her brother's favorite color was ... orange The late musical artist's brand has been all about the color purple (CNN) Tyka Nelson just tweaked a major part of Prince's legacy. The sister of the late superstar talked to the Evening Standard about an upcoming exhibit of Prince artifacts set to open in London and mentioned one of his beloved instruments. \"The standout piece for me is his orange Cloud guitar,\" the publication quoted Nelson as saying. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\n\n\n\n\n**<font color='blue'>Rewriten Text:</font>**\n\nIn the land of musical legends, I stumbled upon a hidden gem that shed light on the enigmatic life of the late Prince. As I ventured through the archives of his legacy, I stumbled upon a revelation that challenged my understanding of the artist's vibrant persona.\n\nThe exhibit, set to open in London, will showcase a collection of Prince's treasured artifacts, including a guitar that held a special place in his heart. \"The standout piece for me is his orange Cloud guitar,\" Nelson said in an interview with the Evening Standard. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\nThis discovery was like a treasure map leading me to a hidden chamber where Prince's soul lived on through the prism of his favorite hue. It was a moment of profound connection to the artist's inner world, revealing a hidden layer of his creative spirit.\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\n\n**Prompt/\n\n**<font color='red'>Instruction:</font>****\n\nThe prompt/instruction given to the LLM to rewrite/transform/improve the text in this way is likely to be:\n\n**1. Expand the scope of the story:** The original text is relatively short and focused primarily on the connection between Tyka Nelson and Prince's favorite color. The rewritten text expands the scope of the story to include a broader overview of Prince's legacy and the exhibit set to open in London.\n\n**2. Use vivid imagery and storytelling:** The rewritten text uses vivid imagery and storytelling techniques to create a more immersive and engaging experience for the reader.\n\n**3. Add a personal touch:** The rewritten text includes a personal touch, such as the author's own experiences and reflections on Prince's legacy.\n\n**4. Use a more formal tone:** The rewritten text uses a more formal tone than the original text, which is more conversational and informal.\n\n**5. Include additional details and information:** The rewritten text includes additional details and information about Prince's legacy and the exhibit set to open in London."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take one sample\n",
    "row = df.iloc[10]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    original_text=row.original_text,\n",
    "    rewritten_text=row.rewritten_text,\n",
    "    rewrite_prompt=\"\",\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = generate_response(prompt)\n",
    "\n",
    "# Colorize\n",
    "output = colorize_text(output)\n",
    "\n",
    "# Display in markdown\n",
    "display(Markdown(output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:43.598230Z",
     "start_time": "2024-04-02T08:05:36.233512Z"
    }
   },
   "id": "b6faa829ce478551",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nRefined mansion tax proposal being fed into debate on abolishing 50p tax rate for those earning more than £150,000 The Liberal Democrats are pushing for the eventual disbanding of the 50p rate of tax to see the implementation of a new land tax levied on properties above £1m. In a refinement of their controversial mansion tax policy launched at their party conference two years ago, the Lib Dems now believe there is an argument for levying capital gains tax on any money made from the sale of a property after the first £1m. The Lib Dem idea is being fed\n\n\n\n\n\n**<font color='blue'>Rewriten Text:</font>**\n\nSure, here is the rephrased text as a wise old tree's advice:\n\n\"My dear young sapling, listen to my wisdom. The path you tread is fraught with challenges, but I have a secret to share that will guide you through.\n\nIn the realm of taxation, there is a tale to be told. A tale of a 50p rate of tax that once stood tall, but has been met with a storm of controversy. The Liberal Democrats, like a seasoned traveler, have devised a refined plan to replace this rate with a new land tax on properties above a million quid.\n\nBut my dear sapling, remember this: the devil is in the details. While the land tax may seem like a noble gesture, the devil lies in the implementation of the capital gains tax on any money made from the sale of a property after the first million. It is a complex web of rules and regulations that can entrap even the most seasoned tax expert.\n\nTherefore, my young sapling, I urge you to tread cautiously and consult the wisdom of those who have gone before you. For in the realm of taxation, the devil is always lurking, and it is only through understanding the intricacies of the law that you can navigate the treacherous terrain.\"\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\n\nThe prompt/instruction given to the LLM to rewrite/transform/improve the text is as follows:\n\n**Prompt:**\n\nPlease rewrite the original text in a more creative and engaging way, using the tone of a wise old tree's advice. Include additional details and information that are not present in the original text.\n\n**Additional instructions:**\n\n* Use a conversational tone that is easy to understand.\n* Use vivid imagery and metaphors to create a more immersive experience for the reader.\n* Include a clear call to action at the end of the text."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take one sample\n",
    "row = df.iloc[20]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    original_text=row.original_text,\n",
    "    rewritten_text=row.rewritten_text,\n",
    "    rewrite_prompt=\"\",\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = generate_response(prompt)\n",
    "\n",
    "# Colorize\n",
    "output = colorize_text(output)\n",
    "\n",
    "# Display in markdown\n",
    "display(Markdown(output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:47.190287Z",
     "start_time": "2024-04-02T08:05:43.599722Z"
    }
   },
   "id": "f2956602b6e6aa09",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Supervised Fine-Tuning (LoRA)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b43eba6780d2e557"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def formatting_func(examples):\n",
    "    text = (f\"Instruction:\\n\\n{examples['prompt']}\\n\\n\"\n",
    "            f\"Original Text:\\n\\n{examples['original_text']}\\n\\n\"\n",
    "            f\"Rewriten Text:\\n\\n{examples['rewritten_text']}\\n\\n\"\n",
    "            f\"Response:\\n\\n{examples['rewrite_prompt']}\")\n",
    "    return [text]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:47.193876Z",
     "start_time": "2024-04-02T08:05:47.191479Z"
    }
   },
   "id": "5149df1d9882f351",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/3600 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08faf17e19de4c1fb9d48a94948c0934"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/400 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46f5cc200fc0410d81055cdb2cc63f04"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathfinder/anaconda3/envs/torch-env/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:317: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "/home/pathfinder/anaconda3/envs/torch-env/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    peft_config=lora_config,\n",
    "    max_seq_length=max_seq_length,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    formatting_func=formatting_func\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:05:58.944215Z",
     "start_time": "2024-04-02T08:05:47.194764Z"
    }
   },
   "id": "c60c5aa9a7d970b3",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4/4 00:42, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.782000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.767500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3.668000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>3.749300</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=4, training_loss=3.7416868805885315, metrics={'train_runtime': 56.4546, 'train_samples_per_second': 0.071, 'train_steps_per_second': 0.071, 'total_flos': 95554570813440.0, 'train_loss': 3.7416868805885315, 'epoch': 1.0})"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:06:55.602939Z",
     "start_time": "2024-04-02T08:05:58.945322Z"
    }
   },
   "id": "5d9ba03835392e2a",
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference after Fine-Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adbd045cf5ca4cc3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nStory highlights Tyka Nelson says her brother's favorite color was ... orange The late musical artist's brand has been all about the color purple (CNN) Tyka Nelson just tweaked a major part of Prince's legacy. The sister of the late superstar talked to the Evening Standard about an upcoming exhibit of Prince artifacts set to open in London and mentioned one of his beloved instruments. \"The standout piece for me is his orange Cloud guitar,\" the publication quoted Nelson as saying. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\n\n\n\n\n**<font color='blue'>Rewriten Text:</font>**\n\nIn the land of musical legends, I stumbled upon a hidden gem that shed light on the enigmatic life of the late Prince. As I ventured through the archives of his legacy, I stumbled upon a revelation that challenged my understanding of the artist's vibrant persona.\n\nThe exhibit, set to open in London, will showcase a collection of Prince's treasured artifacts, including a guitar that held a special place in his heart. \"The standout piece for me is his orange Cloud guitar,\" Nelson said in an interview with the Evening Standard. \"It is strange because people always associate the color purple with Prince, but his favorite color was actually orange.\"\n\nThis discovery was like a treasure map leading me to a hidden chamber where Prince's soul lived on through the prism of his favorite hue. It was a moment of profound connection to the artist's inner world, revealing a hidden layer of his creative spirit.\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\n\n**Prompt/\n\n**<font color='red'>Instruction:</font>****\n\nThe prompt/instruction given to the LLM to rewrite/transform/improve the text in this way is likely to be:\n\n**1. Expand the scope of the story:** The original text is relatively short, so the prompt likely instructed the LLM to expand the story and add more details and descriptions.\n\n**2. Create a more immersive and evocative atmosphere:** The rewritten text is much more descriptive and immersive than the original text, so the prompt likely instructed the LLM to create a more evocative atmosphere.\n\n**3. Use vivid language and imagery:** The rewritten text uses vivid language and imagery to create a more engaging and immersive experience for the reader. The prompt likely instructed the LLM to use vivid language and imagery.\n\n**4. Connect the story to the artist's personality:** The rewritten text connects the story to Prince's personality and legacy. The prompt likely instructed the LLM to connect the story to Prince's personality and legacy.\n\n**5. Add a personal touch:** The rewritten text includes a personal touch, such as the author's own experiences and reflections. The prompt likely instructed the LLM to add a personal touch."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take one sample\n",
    "row = df.iloc[10]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    original_text=row.original_text,\n",
    "    rewritten_text=row.rewritten_text,\n",
    "    rewrite_prompt=\"\",\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = generate_response(prompt)\n",
    "\n",
    "# Colorize\n",
    "output = colorize_text(output)\n",
    "\n",
    "# Display in markdown\n",
    "display(Markdown(output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:07:13.331883Z",
     "start_time": "2024-04-02T08:06:55.603947Z"
    }
   },
   "id": "1ec4f6adea69ec83",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nRefined mansion tax proposal being fed into debate on abolishing 50p tax rate for those earning more than £150,000 The Liberal Democrats are pushing for the eventual disbanding of the 50p rate of tax to see the implementation of a new land tax levied on properties above £1m. In a refinement of their controversial mansion tax policy launched at their party conference two years ago, the Lib Dems now believe there is an argument for levying capital gains tax on any money made from the sale of a property after the first £1m. The Lib Dem idea is being fed\n\n\n\n\n\n**<font color='blue'>Rewriten Text:</font>**\n\nSure, here is the rephrased text as a wise old tree's advice:\n\n\"My dear young sapling, listen to my wisdom. The path you tread is fraught with challenges, but I have a secret to share that will guide you through.\n\nIn the realm of taxation, there is a tale to be told. A tale of a 50p rate of tax that once stood tall, but has been met with a storm of controversy. The Liberal Democrats, like a seasoned traveler, have devised a refined plan to replace this rate with a new land tax on properties above a million quid.\n\nBut my dear sapling, remember this: the devil is in the details. While the land tax may seem like a noble gesture, the devil lies in the implementation of the capital gains tax on any money made from the sale of a property after the first million. It is a complex web of rules and regulations that can entrap even the most seasoned tax expert.\n\nTherefore, my young sapling, I urge you to tread cautiously and consult the wisdom of those who have gone before you. For in the realm of taxation, the devil is always lurking, and it is only through understanding the intricacies of the law that you can navigate the treacherous terrain.\"\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\n\nThe prompt/instruction given to the LLM to rewrite/transform/improve the text is as follows:\n\n**Prompt:**\n\nPlease rewrite the original text in a more creative and engaging way, while maintaining the key points and information. Use a conversational tone and incorporate the use of metaphors and analogies to make the text more relatable and easier to understand."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take one sample\n",
    "row = df.iloc[20]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    original_text=row.original_text,\n",
    "    rewritten_text=row.rewritten_text,\n",
    "    rewrite_prompt=\"\",\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = generate_response(prompt)\n",
    "\n",
    "# Colorize\n",
    "output = colorize_text(output)\n",
    "\n",
    "# Display in markdown\n",
    "display(Markdown(output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:07:18.329349Z",
     "start_time": "2024-04-02T08:07:13.332983Z"
    }
   },
   "id": "4446b42c3d31f196",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference on Test Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4786f147a2c2a05d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   id                                      original_text  \\\n0  -1  The competition dataset comprises text passage...   \n\n                                      rewritten_text  \n0  Here is your shanty: (Verse 1) The text is rew...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>original_text</th>\n      <th>rewritten_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>The competition dataset comprises text passage...</td>\n      <td>Here is your shanty: (Verse 1) The text is rew...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_dataset_path)\n",
    "test_df['original_text'] = test_df['original_text'].fillna(\"\")\n",
    "test_df['rewritten_text'] = test_df['rewritten_text'].fillna(\"\")\n",
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:07:18.340567Z",
     "start_time": "2024-04-02T08:07:18.331422Z"
    }
   },
   "id": "96db4fa1e0ab004b",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n\n\n**<font color='red'>Instruction:</font>**\n\nBelow, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\n\n\n\n\n\n**<font color='yellow'>Original Text:</font>**\n\nThe competition dataset comprises text passages that have been rewritten by the Gemma LLM according to some rewrite_prompt instruction. The goal of the competition is to determine what prompt was used to rewrite each original text.  Please note that this is a Code Competition. When your submission is scored, this example test data will be replaced with the full test set. Expect roughly 2,000 original texts in the test set.\n\n\n\n\n\n**<font color='blue'>Rewriten Text:</font>**\n\nHere is your shanty: (Verse 1) The text is rewritten, the LLM has spun, With prompts so clever, they've been outrun. The goal is to find, the prompt so bright, To crack the code, and shine the light. (Chorus) Oh, this is a code competition, my dear, With text and prompts, we'll compete. Two thousand texts, a challenge grand, To guess the prompts, hand over hand.(Verse 2) The original text, a treasure lost, The rewrite prompt, a secret to be\n\n\n\n\n\n**<font color='green'>Response:</font>**\n\n\nThe prompt/instruction given to the LLM to rewrite/transform/improve the text in this way is likely to be:\n\n**Prompt:**\n\n\"Rewrite the original text in a creative and engaging way, using vivid imagery and a conversational tone. The rewritten text should be approximately the same length as the original text, and should include the main points of the original text, but rearranged in a more entertaining way. Please use your imagination and creativity to craft a compelling rewrite that will capture the imagination of the reader.\""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Data: Take one sample\n",
    "row = test_df.iloc[0]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    original_text=row.original_text,\n",
    "    rewritten_text=row.rewritten_text,\n",
    "    rewrite_prompt=\"\",\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = generate_response(prompt)\n",
    "\n",
    "# Colorize\n",
    "output = colorize_text(output)\n",
    "\n",
    "# Display in markdown\n",
    "display(Markdown(output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:07:25.592893Z",
     "start_time": "2024-04-02T08:07:18.341741Z"
    }
   },
   "id": "12246d824cae27c",
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c44eb9027c933fa1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(output_dir)\n",
    "model.save_pretrained(output_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:07:56.024448Z",
     "start_time": "2024-04-02T08:07:25.594143Z"
    }
   },
   "id": "b11a8e4350831e15",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Submission"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6a2bd457698cded"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.26s/it]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for i in tqdm(range(len(test_df))):\n",
    "    row = test_df.iloc[i]\n",
    "\n",
    "    # Generate Prompt using template\n",
    "    prompt = template.format(\n",
    "        original_text=row.original_text,\n",
    "        rewritten_text=row.rewritten_text,\n",
    "        rewrite_prompt=\"\"\n",
    "    )\n",
    "\n",
    "    # Infer\n",
    "    output = generate_response(prompt)\n",
    "    pred = output.replace(prompt, \"\") # remove the prompt from output\n",
    "    \n",
    "    # Store predictions\n",
    "    preds.append([row.id, pred])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:08:04.289340Z",
     "start_time": "2024-04-02T08:07:56.025603Z"
    }
   },
   "id": "61c9ed3d83ad81b",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   id                                     rewrite_prompt\n0  -1  The prompt/instruction given to the LLM to rew...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>rewrite_prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>The prompt/instruction given to the LLM to rew...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.DataFrame(preds, columns=[\"id\", \"rewrite_prompt\"])\n",
    "sub_df['rewrite_prompt'] = sub_df['rewrite_prompt'].fillna(\"\")\n",
    "sub_df['rewrite_prompt'] = sub_df['rewrite_prompt'].map(lambda x: \"Improve the essay\" if len(x) == 0 else x)\n",
    "sub_df.to_csv(\"submission.csv\",index=False)\n",
    "sub_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:08:04.305617Z",
     "start_time": "2024-04-02T08:08:04.290646Z"
    }
   },
   "id": "36b3a4c15d33b310",
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
